[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.html",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.html",
    "title": "Hands-on Exercise 01: ggplot2 Methods",
    "section": "",
    "text": "In this first lesson, we learn to plot statistical graphics using ggplot2, which is a system created based on the principles of “Layered Grammar of Graphics”. The Layered Grammar of Graphics provide a framework to build a visualisation in a structured and defined manner1. ggplot2 is one of the packages in the tidyverse set of packages."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#loading-required-library",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#loading-required-library",
    "title": "Hands-on Exercise 01: ggplot2 Methods",
    "section": "2.1. Loading Required Library",
    "text": "2.1. Loading Required Library\nFirst, we will load the tidyverse package into the R environment. We will do so using the pacman package, which can be installed using the following code:\n\ninstall.packages('pacman')\n\nWithout loading pacman into the R environment, we can call its p_load function using pacman:: as shown in the code below:\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#import-data",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#import-data",
    "title": "Hands-on Exercise 01: ggplot2 Methods",
    "section": "2.2. Import Data",
    "text": "2.2. Import Data\nNext, we will read the data provided by the Course Instructor into the R environment. We will use the read_csv() function from the readr package found in tidyverse.\n\nNote: use read_csv() from the readr package instead of read.csv() from the R base package. read_csv() is typically faster, produces tibble tables and are more reproducible.\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\nglimpse(exam_data)\n\nRows: 322\nColumns: 7\n$ ID      &lt;chr&gt; \"Student321\", \"Student305\", \"Student289\", \"Student227\", \"Stude…\n$ CLASS   &lt;chr&gt; \"3I\", \"3I\", \"3H\", \"3F\", \"3I\", \"3I\", \"3I\", \"3I\", \"3I\", \"3H\", \"3…\n$ GENDER  &lt;chr&gt; \"Male\", \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Male\", \"M…\n$ RACE    &lt;chr&gt; \"Malay\", \"Malay\", \"Chinese\", \"Chinese\", \"Malay\", \"Malay\", \"Chi…\n$ ENGLISH &lt;dbl&gt; 21, 24, 26, 27, 27, 31, 31, 31, 33, 34, 34, 36, 36, 36, 37, 38…\n$ MATHS   &lt;dbl&gt; 9, 22, 16, 77, 11, 16, 21, 18, 19, 49, 39, 35, 23, 36, 49, 30,…\n$ SCIENCE &lt;dbl&gt; 15, 16, 16, 31, 25, 16, 25, 27, 15, 37, 42, 22, 32, 36, 35, 45…\n\n\nUsing glimpse to view the data, it is observed that the data contains the examination grades of a batch of primary 3 students for the subjects English, Maths, and Science."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#r-graphics-vs-ggplot2",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#r-graphics-vs-ggplot2",
    "title": "Hands-on Exercise 01: ggplot2 Methods",
    "section": "3.1. R Graphics vs ggplot2",
    "text": "3.1. R Graphics vs ggplot2\nFirst, we will do a comparison between the core graphical function of Base R, R Graphics, and ggplot2.\n\nR Graphicsggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 10, \n                 boundary = 100,\n                 color = \"black\",\n                 fill = 'grey') +\n  ggtitle(\"Distribution of Maths Scores in Primary 3 Cohort\")\n\n\n\n\n\n\n\nIt is relatively simple to create a statistical graph using R Graphics, but ggplot2 offers more versatility and flexibility in the way data is presented visually."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#layered-grammar-of-graphics",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#layered-grammar-of-graphics",
    "title": "Hands-on Exercise 01: ggplot2 Methods",
    "section": "4.1. Layered Grammar of Graphics",
    "text": "4.1. Layered Grammar of Graphics\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics with seven layers:\n\nData: the data set used for plotting\nAesthetics: use attributes of the data to influence visual characteristics\nGeometrics: visual elements used for the data such as point, bar or line\nFacets: create multiple variations of the same graph by splitting data into subsets such as paneling and multiple plots\nStatistics: statistical transformation to summarise the data such as mean and confidence intervals\nCoordinate systems: define the plane on which data is mapped on the graphic\nThemes: non-data elements of the plot such as main title, axis title, legend background\n\nWe will explore each layer in the subsequent sub-sections."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#modifying-a-geometric-object-using-geom",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#modifying-a-geometric-object-using-geom",
    "title": "Hands-on Exercise 01: ggplot2 Methods",
    "section": "7.9. Modifying a geometric object using geom()",
    "text": "7.9. Modifying a geometric object using geom()\nWe can customize a plot by adjusting the arguments within geom(), such as:\n\nggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#modifying-a-geometric-object-using-aes",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#modifying-a-geometric-object-using-aes",
    "title": "Hands-on Exercise 01: ggplot2 Methods",
    "section": "7.10. Modifying a geometric object using aes()",
    "text": "7.10. Modifying a geometric object using aes()\nWe can add more details into the plot by adjusting the fill colour of the histogram by adjusting the arguments in aes():\n\nggplot(data = exam_data, \n       aes(x = MATHS,\n           fill = GENDER)) +\n  geom_histogram(bins = 20,\n                 color = \"grey30\")\n\n\n\n\nNote: This approach can be used to adjust the colour, fill, and alpha of the geometric object."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#using-stat_summary",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#using-stat_summary",
    "title": "Hands-on Exercise 01: ggplot2 Methods",
    "section": "8.1. Using stat_summary()",
    "text": "8.1. Using stat_summary()\nWe can use the stat_summary() function to add mean values into a plot. We use the boxplot as an example:\n\nggplot(data = exam_data, \n       aes(y = MATHS,\n           x = GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"red\",\n               size = 4)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#using-the-geom-method",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#using-the-geom-method",
    "title": "Hands-on Exercise 01: ggplot2 Methods",
    "section": "8.2. Using the geom() Method",
    "text": "8.2. Using the geom() Method\nMean values can also be added through the geom() function:\n\nggplot(data = exam_data, \n       aes(y = MATHS,\n           x = GENDER)) +\n  geom_boxplot() +\n  geom_point(stat = \"summary\",\n             fun.y  = \"mean\",\n             color = \"red\",\n             size = 4)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#add-best-fit-curve-to-scatterplot",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#add-best-fit-curve-to-scatterplot",
    "title": "Hands-on Exercise 01: ggplot2 Methods",
    "section": "8.3. Add Best Fit Curve to Scatterplot",
    "text": "8.3. Add Best Fit Curve to Scatterplot\nWe can use geom_smooth() to plot a best fit curve on the scatterplot:\n\nggplot(data = exam_data, \n       aes(y = MATHS,\n           x = ENGLISH)) +\n  geom_point() +\n  geom_smooth(size = 0.5)\n\n\n\n\nThe default method used is loess, and this can be changed by specifying the preferred method:\n\nggplot(data = exam_data, \n       aes(y = MATHS,\n           x = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#facet_wrap",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#facet_wrap",
    "title": "Hands-on Exercise 01: ggplot2 Methods",
    "section": "9.1 facet_wrap()",
    "text": "9.1 facet_wrap()\nfacet_wrap() wraps a 1d sequence of panels into 2d, which is a better use of screen space than facet_grid():\n\nggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_histogram(bins = 20) +\n  facet_wrap(~ CLASS)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#facet_grid",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#facet_grid",
    "title": "Hands-on Exercise 01: ggplot2 Methods",
    "section": "9.2. facet_grid()",
    "text": "9.2. facet_grid()\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when used with two discrete variables, and all combinations of the variables exist in the data.\n\nggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_histogram() +\n  facet_grid(~ CLASS)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#coord_flip",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#coord_flip",
    "title": "Hands-on Exercise 01: ggplot2 Methods",
    "section": "10.1. coord_flip()",
    "text": "10.1. coord_flip()\n\nOriginalcoord_flip()\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar()\n\n\n\n\n\n\ncoord_flip() flips the vertical bar charts into horizontal bar charts:\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar() +\n  coord_flip()"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#changing-the-range-of-the-y--and-x-axes",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#changing-the-range-of-the-y--and-x-axes",
    "title": "Hands-on Exercise 01: ggplot2 Methods",
    "section": "10.2. Changing the range of the y- and x-axes",
    "text": "10.2. Changing the range of the y- and x-axes\n\nOriginalcoord_cartesian()\n\n\n\nggplot(data = exam_data,\n       aes(x = MATHS,\n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5)\n\n\n\n\nWe can observe that the y- and x-axes in the plot is not equal and could appear as misleading.\n\n\nWe can use coord_cartesian() to set the limits of both the x- and y-axes from 0 to 100.\n\nggplot(data = exam_data,\n       aes(x = MATHS,\n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100))"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#footnotes",
    "href": "hands_on_ex/hands_on_ex01/hands_on_ex01.html#footnotes",
    "title": "Hands-on Exercise 01: ggplot2 Methods",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://towardsdatascience.com/a-comprehensive-guide-to-the-grammar-of-graphics-for-effective-visualization-of-multi-dimensional-1f92b4ed4149↩︎"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.html",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.html",
    "title": "Hands-on Exercise 02: Customising ggplot2 Plots",
    "section": "",
    "text": "In this second lesson, we learn about ggplot2 extensions that helps us to create elegant and effective statistical graphs."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#installing-and-loading-packages",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#installing-and-loading-packages",
    "title": "Hands-on Exercise 02: Customising ggplot2 Plots",
    "section": "2.1. Installing and Loading Packages",
    "text": "2.1. Installing and Loading Packages\nWe will use the following R packages in addition to tidyverse for this exercise:\n\nggrepel: provides geoms forggplot2to repel overlapping text labels\nggthemes: provides extra themes, geoms, and scales forggplot2\nhrbrthemes: provides typography-centric themes and theme components for ggplot2\npatchwork: to make plot composition using ggplot2 simple and powerful\n\nThe packages to be used can be installed and loaded into the R environment using the p_load() function from the pacman package:\n\npacman::p_load(tidyverse, ggrepel, ggthemes, \n               hrbrthemes, patchwork)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#import-data",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#import-data",
    "title": "Hands-on Exercise 02: Customising ggplot2 Plots",
    "section": "2.2. Import Data",
    "text": "2.2. Import Data\nNext, we will read the data provided by the Course Instructor into the R environment. We will use the read_csv() function from the readr package found in tidyverse.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\nglimpse(exam_data)\n\nRows: 322\nColumns: 7\n$ ID      &lt;chr&gt; \"Student321\", \"Student305\", \"Student289\", \"Student227\", \"Stude…\n$ CLASS   &lt;chr&gt; \"3I\", \"3I\", \"3H\", \"3F\", \"3I\", \"3I\", \"3I\", \"3I\", \"3I\", \"3H\", \"3…\n$ GENDER  &lt;chr&gt; \"Male\", \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Male\", \"M…\n$ RACE    &lt;chr&gt; \"Malay\", \"Malay\", \"Chinese\", \"Chinese\", \"Malay\", \"Malay\", \"Chi…\n$ ENGLISH &lt;dbl&gt; 21, 24, 26, 27, 27, 31, 31, 31, 33, 34, 34, 36, 36, 36, 37, 38…\n$ MATHS   &lt;dbl&gt; 9, 22, 16, 77, 11, 16, 21, 18, 19, 49, 39, 35, 23, 36, 49, 30,…\n$ SCIENCE &lt;dbl&gt; 15, 16, 16, 31, 25, 16, 25, 27, 15, 37, 42, 22, 32, 36, 35, 45…\n\n\nUsing glimpse to view the data, it is observed that the data contains the examination grades of a batch of primary 3 students for the subjects English, Maths, and Science."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#ggthemes",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#ggthemes",
    "title": "Hands-on Exercise 02: Customising ggplot2 Plots",
    "section": "4.1. ggthemes",
    "text": "4.1. ggthemes\nggthemes provides additional ggplot2 themes that replicate the look of plots by Edward Tufte, The Economist, Stata, Microsoft Excel, and The Wall Street Journal.\n\ntheme_economist()theme_stata()theme_excel_new()\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar() +\n  coord_flip() + \n  theme_economist() + \n  ggtitle(\"Distribution of Students by Race\")\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar() +\n  coord_flip() + \n  theme_stata() + \n  ggtitle(\"Distribution of Students by Race\")\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar() +\n  coord_flip() + \n  theme_excel_new() + \n  ggtitle(\"Distribution of Students by Race\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#hrbrthemes",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#hrbrthemes",
    "title": "Hands-on Exercise 02: Customising ggplot2 Plots",
    "section": "4.2. hrbrthemes",
    "text": "4.2. hrbrthemes\nhrbrthemes provide typograhic-centric themes to adjust the labels and fonts used in a ggplot2 graph.\n\ntheme_ipsum()theme_ipsum_es()Production Workflow\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar() +\n  coord_flip() + \n  theme_ipsum() + \n  ggtitle(\"Distribution of Students by Race\")\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar() +\n  coord_flip() + \n  theme_ipsum_es() + \n  ggtitle(\"Distribution of Students by Race\")\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar() +\n  coord_flip() + \n  theme_ipsum(axis_title_size = 16,\n              base_size = 15,\n              grid = \"Y\") + \n  ggtitle(\"Distribution of Students by Race\")\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\naxis_title_size(): to adjust font size of the axis title\nbase_size(): to adjust default axis label\ngrid(): to remove x-axis grid lines"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#combining-two-ggplot2-graphs",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#combining-two-ggplot2-graphs",
    "title": "Hands-on Exercise 02: Customising ggplot2 Plots",
    "section": "5.1. Combining Two ggplot2 Graphs",
    "text": "5.1. Combining Two ggplot2 Graphs\n\npatchworkggpubrgridExtracowplot\n\n\n\nmaths + english\n\n\n\n\n\nmaths / english\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nuse + to add plots to form a patchwork (keeps the grid as square as possible)\nuse / to place plots on top of each other\nuse | to place plots next to each other\nuse () to create a subplot group\n\n\n\n\n\n\npacman::p_load(ggpubr)\nggarrange(maths, english)\n\n\n\n\n\n\n\npacman::p_load(gridExtra)\ngrid.arrange(maths, english, ncol = 2, nrow = 1)\n\n\n\n\n\n\n\npacman::p_load(cowplot)\nplot_grid(maths, english, ncol = 2, nrow = 1)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#combining-three-ggplot2-graphs",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#combining-three-ggplot2-graphs",
    "title": "Hands-on Exercise 02: Customising ggplot2 Plots",
    "section": "5.2. Combining Three ggplot2 Graphs",
    "text": "5.2. Combining Three ggplot2 Graphs\n\npatchworkggpubrgridExtracowplot\n\n\n\n(maths / english) | maths_vs_eng\n\n\n\n\n\nmaths_vs_eng / (maths | english)\n\n\n\n\n\n\n\nleft &lt;- ggarrange(maths, english, ncol = 1)\nggarrange(left, maths_vs_eng)\n\n\n\n\n\n\n\ngrid.arrange(arrangeGrob(maths, english), maths_vs_eng, ncol = 2)\n\n\n\n\n\n\n\nleft &lt;- plot_grid(maths, english, ncol = 1) \nplot_grid(left, maths_vs_eng)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#create-composite-figure-with-tags",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#create-composite-figure-with-tags",
    "title": "Hands-on Exercise 02: Customising ggplot2 Plots",
    "section": "5.3. Create Composite Figure with Tags",
    "text": "5.3. Create Composite Figure with Tags\n\npatchworkggpubrgridExtracowplot\n\n\n\n((maths / english) | maths_vs_eng) +\n  plot_annotation(tag_levels = \"A\")\n\n\n\n\n\n\n\nright &lt;- ggarrange(maths_vs_eng, ncol = 1, labels = \"C\")\nggarrange(ggarrange(maths, english, ncol = 1, labels = c(\"A\",\"B\")), right)\n\n\n\n\n\n\nThere is no direct method to create labels using gridExtra. Hence, the labels have to first be added to each individual plot before they are combined together using grid.arrange().\n\nmaths_E &lt;- ggplot(data = exam_data,\n                aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"grey30\",\n                 fill = \"grey90\") +\n  coord_cartesian(xlim = c(0,100)) +\n  ggtitle(\"Distribution of Maths Scores\") + \n  labs(tag = \"A\")\n\nenglish_E &lt;- ggplot(data = exam_data,\n                aes(x = ENGLISH)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"grey30\",\n                 fill = \"grey90\") +\n  coord_cartesian(xlim = c(0,100)) +\n  ggtitle(\"Distribution of English Scores\") +\n  labs(tag = \"B\")\n\nmaths_vs_eng_E &lt;- ggplot(data = exam_data,\n                aes(x = MATHS,\n                    y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle(\"English vs Maths Scores\") +\n  labs(tag = \"C\")\n\n\ngrid.arrange(arrangeGrob(maths_E, english_E), maths_vs_eng_E, ncol = 2)\n\n\n\n\n\n\n\nleft &lt;- plot_grid(maths, english, ncol = 1, labels = c(\"A\",\"B\")) \nplot_grid(left, maths_vs_eng, labels = c(\"\",\"C\"))"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#create-figure-with-inset",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#create-figure-with-inset",
    "title": "Hands-on Exercise 02: Customising ggplot2 Plots",
    "section": "5.4. Create Figure with Inset",
    "text": "5.4. Create Figure with Inset\n\npatchworkcowplot\n\n\n\nmaths_vs_eng +\n  inset_element(maths,\n                left = 0.01,\n                bottom = 0.7, \n                right = 0.5,\n                top = 1)\n\n\n\n\n\n\n\nggdraw(maths_vs_eng) +\n  draw_plot(maths, 0.1,0.7,0.5,0.3)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#adding-themes-to-composite-figure",
    "href": "hands_on_ex/hands_on_ex02/hands_on_ex02.html#adding-themes-to-composite-figure",
    "title": "Hands-on Exercise 02: Customising ggplot2 Plots",
    "section": "5.5. Adding Themes to Composite Figure",
    "text": "5.5. Adding Themes to Composite Figure\nFinally, we can add finishing touches to the composite figure by using & with the desired theme:\n\n((maths / english) | maths_vs_eng) & theme_economist()"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html",
    "title": "Hands-on Exercise 03 - Interactive Visualisation",
    "section": "",
    "text": "In the first part of the third lesson, we learn to create interactive data visualisations using ggiraph and plotly packages."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#installing-and-loading-packages",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#installing-and-loading-packages",
    "title": "Hands-on Exercise 03 - Interactive Visualisation",
    "section": "2.1. Installing and Loading Packages",
    "text": "2.1. Installing and Loading Packages\nWe will use the following R packages in addition to tidyverse and patchwork for this exercise:\n\nggiraph: makes R graphing library interactive (additional resource: ggiraph-book)\nplotly: provides extra themes, geoms, and scales forggplot2\nDT: provides R interface to the JavaScript library DataTables to create interactive tables on html pages\n\nThe packages to be used can be installed and loaded into the R environment using the p_load() function from the pacman package:\n\npacman::p_load(tidyverse, patchwork, \n               ggiraph, plotly, DT)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#import-data",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#import-data",
    "title": "Hands-on Exercise 03 - Interactive Visualisation",
    "section": "2.2. Import Data",
    "text": "2.2. Import Data\nNext, we will read the data provided by the Course Instructor into the R environment. We will use the read_csv() function from the readr package found in tidyverse.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\nglimpse(exam_data)\n\nRows: 322\nColumns: 7\n$ ID      &lt;chr&gt; \"Student321\", \"Student305\", \"Student289\", \"Student227\", \"Stude…\n$ CLASS   &lt;chr&gt; \"3I\", \"3I\", \"3H\", \"3F\", \"3I\", \"3I\", \"3I\", \"3I\", \"3I\", \"3H\", \"3…\n$ GENDER  &lt;chr&gt; \"Male\", \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Male\", \"M…\n$ RACE    &lt;chr&gt; \"Malay\", \"Malay\", \"Chinese\", \"Chinese\", \"Malay\", \"Malay\", \"Chi…\n$ ENGLISH &lt;dbl&gt; 21, 24, 26, 27, 27, 31, 31, 31, 33, 34, 34, 36, 36, 36, 37, 38…\n$ MATHS   &lt;dbl&gt; 9, 22, 16, 77, 11, 16, 21, 18, 19, 49, 39, 35, 23, 36, 49, 30,…\n$ SCIENCE &lt;dbl&gt; 15, 16, 16, 31, 25, 16, 25, 27, 15, 37, 42, 22, 32, 36, 35, 45…"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#tooltip-aesthetic",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#tooltip-aesthetic",
    "title": "Hands-on Exercise 03 - Interactive Visualisation",
    "section": "3.1. tooltip Aesthetic",
    "text": "3.1. tooltip Aesthetic\nThis is a typical code chunk to plot an interactive statistical graph using the ggiraph package. We first create an interactive version of ggplot object and store it as a variable before passing it into the girafe() function from the ggiraph package to create an interactive svg object.\n\nmaths &lt;- ggplot(data = exam_data,\n                aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = maths,\n       width_svg = 6,\n       height_svg = 6 * 0.618)\n\n\n\n\n\nIt is observed that as we point the cursor at any point in the graph, the respective student’s ID appears in a small popup box.\n\n3.1.1. Displaying Multiple Information on tooltip\nWe can customise the tooltip by including a list object to be displayed. For example, we want to display the student’s name and class in the tooltip below:\n\nexam_data$tooltip &lt;- c(paste0(\n  \"Name = \", exam_data$ID,\n  \"\\n Class = \", exam_data$CLASS))\n\nmaths &lt;- ggplot(data = exam_data,\n                aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = maths,\n       width_svg = 6,\n       height_svg = 6 * 0.618)\n\n\n\n\n\nIn this example, we create a new column in the exam_data tibble table where ID and CLASS are populated. paste0 is used to populate this column and its function is to concatenate the input values in a single character string, where the sep argument is “” (without space) by default. We then call this newly created column to be used as the tooltip field, instead of using ID only.\n\n\n3.1.2. Customising tooltip Style\nWe can use the opts_tooltip() function from ggiraph to customise the tooltip via css declarations.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-colour:bold; color:black;\" #&lt;&lt;\n\nmaths &lt;- ggplot(data = exam_data,\n                aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = maths,\n       width_svg = 6,\n       height_svg = 6 * 0.618,\n       options = list(  #&lt;&lt;\n         opts_tooltip(  #&lt;&lt;\n           css = tooltip_css)) #&lt;&lt;\n       )\n\n\n\n\n\n\n\n3.1.3. Displaying Statistics on tooltip\nWe can use a function to compute statistics and display them on the tooltip. In this example, we compute the 90% confidence interval of the mean and display it in the tooltip,\n\ntooltip &lt;- function(y, ymax, accuracy = 0.1) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths score:\", mean, \"+/-\", sem)\n}\n\ngg_pt &lt;- ggplot(data = exam_data,\n                aes(x = RACE),\n                ) +\n  stat_summary(aes(y = MATHS,\n                   tooltip = after_stat(\n                     tooltip(y, ymax))),\n               fun.data = \"mean_se\",\n               geom = GeomInteractiveCol,\n               fill = \"lightblue\"\n               ) +\n  stat_summary(aes(y = MATHS),\n               fun.data = mean_se,\n               geom = \"errorbar\", width = 0.2, linewidth = 0.2)\n\ngirafe(ggobj = gg_pt,\n       width_svg = 8,\n       height_svg = 8*0.618)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#data_id-aesthetic",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#data_id-aesthetic",
    "title": "Hands-on Exercise 03 - Interactive Visualisation",
    "section": "3.2. data_id Aesthetic",
    "text": "3.2. data_id Aesthetic\nNext, we explore the use of the data_id aesthetic in the ggiraph package.\n\nmaths &lt;- ggplot(data = exam_data,\n                aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = CLASS,\n        tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = maths,\n       width_svg = 6,\n       height_svg = 6 * 0.618)\n\n\n\n\n\nIt is observed as the cursor hovers over each point, elements associated with the defined data_id (CLASS in this case) are highlighted in the default orange fill - hover_css=\"fill:orange;\".\n\n3.2.1. Styling data_id Aesthetic\nWe can customise the style of the highlighted elements when using the data_id aesthetic.\n\nmaths &lt;- ggplot(data = exam_data,\n                aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = maths,\n       width_svg = 6,\n       height_svg = 6 * 0.618,\n       options = list(\n         opts_hover(css = \"fill:#202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n       ))\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nCSS colour codes can be obtained on this link :)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#combining-tooltip-and-data_id",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#combining-tooltip-and-data_id",
    "title": "Hands-on Exercise 03 - Interactive Visualisation",
    "section": "3.3. Combining tooltip and data_id",
    "text": "3.3. Combining tooltip and data_id\nNext, we explore a method to display tooltip information when the cursor is hovering over a data point.\n\nmaths &lt;- ggplot(data = exam_data,\n                aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = CLASS,\n        data_id = CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = maths,\n       width_svg = 6,\n       height_svg = 6 * 0.618,\n       options = list(\n         opts_hover(css = \"fill:#202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n       ))"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#onclick-aesthetic",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#onclick-aesthetic",
    "title": "Hands-on Exercise 03 - Interactive Visualisation",
    "section": "3.4. onclick Aesthetic",
    "text": "3.4. onclick Aesthetic\nWe can use the onclick aesthetic to provide hotlink interactivity, such as opening a new web browser window when the graph is clicked. The click action must be stored in a column in the dataset as a string data type that contains valid JavaScript instructions. An example is shown below:\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n                             \"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\n                             as.character(exam_data$ID))\n\nmaths &lt;- ggplot(data = exam_data,\n                aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(onclick = onclick),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = maths,\n       width_svg = 6,\n       height_svg = 6 * 0.618)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#coordinated-multiple-views",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#coordinated-multiple-views",
    "title": "Hands-on Exercise 03 - Interactive Visualisation",
    "section": "3.5. Coordinated Multiple Views",
    "text": "3.5. Coordinated Multiple Views\nWhen displaying two plots side-by-side, we may hover over a data point on the first plot and have the same data point highlighted in the second plot. This can be done by combining multiple plots, each created with an interactive function from ggiraph, using patchwork. An example is shown below:\n\nmaths &lt;- ggplot(data = exam_data,\n                aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID,\n        tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\neng &lt;- ggplot(data = exam_data,\n                aes(x = ENGLISH)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID,\n        tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\nsci &lt;- ggplot(data = exam_data,\n                aes(x = SCIENCE)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID,\n        tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(code = print(maths + eng + sci),\n       width_svg = 8,\n       height_svg = 2,\n       options = list(\n         opts_hover(css = \"fill:#202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n       ))"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#plot_ly-vs-ggplotly",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#plot_ly-vs-ggplotly",
    "title": "Hands-on Exercise 03 - Interactive Visualisation",
    "section": "4.1. plot_ly() vs ggplotly()",
    "text": "4.1. plot_ly() vs ggplotly()\nWe create a scatterplot as an example to compare the methods between plot_ly() and ggplotly().\n\nplot_ly()ggplotly()\n\n\n\nplot_ly(data = exam_data,\n        x = ~MATHS,\n        y = ~ENGLISH,\n        color = ~RACE)\n\n\n\n\n\n\n\n\nmaths_eng &lt;- ggplot(data = exam_data,\n                    aes(x = MATHS,\n                        y = ENGLISH,\n                        color = RACE)) +\n  geom_point(size = 1) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100))\n\nggplotly(maths_eng)\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe create the plot and store it as a variable before passing it into ggplotly().\nWe see that interactive tools are included at the top right hand corner of the plot using ggplotly()."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#coordinated-multiple-views-1",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#coordinated-multiple-views-1",
    "title": "Hands-on Exercise 03 - Interactive Visualisation",
    "section": "4.2. Coordinated Multiple Views",
    "text": "4.2. Coordinated Multiple Views\nThe following steps are involved in the creation of a coordinated linked plot using plotly:\n\nuse highlight_key() from the plotly package to create shared data\ncreate two plots using ggplot2 functions\nuse subplot() function from the plotly package to place both plots side-by-side\n\n\n# Step 1: create shared data\nexamdata &lt;- highlight_key(exam_data)\n\n# Step 2: Create two plots\n# data = must point to the shared data created in step 1\nmaths_eng &lt;- ggplot(data = examdata,\n                    aes(x = MATHS,\n                        y = ENGLISH,\n                        color = RACE)) +\n  geom_point(size = 1) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100))\n\nmaths_sci &lt;- ggplot(data = examdata,\n                    aes(x = MATHS,\n                        y = SCIENCE,\n                        color = RACE)) +\n  geom_point(size = 1) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100))\n\n# Step 3: Place both plots side-by-side\n# use subplot function instead of patchwork\nsubplot(ggplotly(maths_eng),\n        ggplotly(maths_sci))"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#linked-brushing-using-crosstalk",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03.html#linked-brushing-using-crosstalk",
    "title": "Hands-on Exercise 03 - Interactive Visualisation",
    "section": "5.1. Linked Brushing Using crosstalk",
    "text": "5.1. Linked Brushing Using crosstalk\n\nexamdata &lt;- highlight_key(exam_data)\n\nmaths_eng &lt;- ggplot(data = examdata,\n                    aes(ENGLISH,\n                        MATHS)) +\n  geom_point(size = 1) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100))\n\ngg &lt;- highlight(ggplotly(maths_eng),\n                \"plotly_selected\")\n\ncrosstalk::bscols(gg,\n                  datatable(examdata),\n                  widths = 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nUsing crosstalk, we are able to link interactive functions such as highlighting selected data points and display the details of the selected points in the table."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03_2.html",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03_2.html",
    "title": "Hands-on Exercise 03 - Animated Data Visualisations",
    "section": "",
    "text": "In the second part of the third lesson, we learn to create animated data visualisations using gganimate and plotly packages."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03_2.html#installing-and-loading-packages",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03_2.html#installing-and-loading-packages",
    "title": "Hands-on Exercise 03 - Animated Data Visualisations",
    "section": "2.1. Installing and Loading Packages",
    "text": "2.1. Installing and Loading Packages\nWe will use the following R packages in addition to tidyverse and plotly for this exercise:\n\ngganimate: ggplot2 extension to create animated statistical graphs\ngifski: creates GIF animations\ngapminder: an excerpt of the data availabe on gapminder.org. We will use it country_colors scheme.\n\nThe packages to be used can be installed and loaded into the R environment using the p_load() function from the pacman package.\n\npacman::p_load(tidyverse, plotly, \n               gganimate, gifski, gapminder)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex03/hands_on_ex03_2.html#import-data",
    "href": "hands_on_ex/hands_on_ex03/hands_on_ex03_2.html#import-data",
    "title": "Hands-on Exercise 03 - Animated Data Visualisations",
    "section": "2.2. Import Data",
    "text": "2.2. Import Data\nNext, we will read the data provided by the Course Instructor into the R environment. As the data is in .xls format, we will use the read_xls() function from the readxl package. We will call the function without loading the package into the environment:\n\nglobal_pop &lt;- readxl::read_xls(\"data/GlobalPopulation.xls\",\n                               sheet=\"Data\")\nglimpse(global_pop)\n\nRows: 6,204\nColumns: 6\n$ Country    &lt;chr&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\",…\n$ Year       &lt;dbl&gt; 1996, 1998, 2000, 2002, 2004, 2006, 2008, 2010, 2012, 2014,…\n$ Young      &lt;dbl&gt; 83.6, 84.1, 84.6, 85.1, 84.5, 84.3, 84.1, 83.7, 82.9, 82.1,…\n$ Old        &lt;dbl&gt; 4.5, 4.5, 4.5, 4.5, 4.5, 4.6, 4.6, 4.6, 4.6, 4.7, 4.7, 4.7,…\n$ Population &lt;dbl&gt; 21559.9, 22912.8, 23898.2, 25268.4, 28513.7, 31057.0, 32738…\n$ Continent  &lt;chr&gt; \"Asia\", \"Asia\", \"Asia\", \"Asia\", \"Asia\", \"Asia\", \"Asia\", \"As…\n\n\nUsing glimpse(), we can see that the records under Country and Continent are recorded as chr, while Year is recorded as dbl. We will use the following code to change Country and Continent to factor data type, and Year to integer data type.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobal_pop &lt;- global_pop %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nglimpse(global_pop)\n\nRows: 6,204\nColumns: 6\n$ Country    &lt;fct&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\",…\n$ Year       &lt;int&gt; 1996, 1998, 2000, 2002, 2004, 2006, 2008, 2010, 2012, 2014,…\n$ Young      &lt;dbl&gt; 83.6, 84.1, 84.6, 85.1, 84.5, 84.3, 84.1, 83.7, 82.9, 82.1,…\n$ Old        &lt;dbl&gt; 4.5, 4.5, 4.5, 4.5, 4.5, 4.6, 4.6, 4.6, 4.6, 4.7, 4.7, 4.7,…\n$ Population &lt;dbl&gt; 21559.9, 22912.8, 23898.2, 25268.4, 28513.7, 31057.0, 32738…\n$ Continent  &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia,…"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html",
    "title": "Hands-on Exercise 04 - Visualising Distributions",
    "section": "",
    "text": "In the first part of the fourth lesson, we learn to visualise distributions using ridgeline and raincloud plots by using ggplot2 and its extensions."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#installing-and-loading-packages",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#installing-and-loading-packages",
    "title": "Hands-on Exercise 04 - Visualising Distributions",
    "section": "2.1. Installing and Loading Packages",
    "text": "2.1. Installing and Loading Packages\nWe will use the following R packages in addition to tidyverse and ggthemes for this exercise:\n\nggdist: ggplot2 extension designed for visualising distributions and uncertainty\nggridges: to create partially overlapping line plots to visualise changes in distribution over time or space\ncolorspace: toolbox for manipulating colours and palettes\n\nThe packages to be used can be installed and loaded into the R environment using the p_load() function from the pacman package:\n\npacman::p_load(tidyverse, ggthemes, \n               ggdist, ggridges, colorspace, plotly)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#import-data",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#import-data",
    "title": "Hands-on Exercise 04 - Visualising Distributions",
    "section": "2.2. Import Data",
    "text": "2.2. Import Data\nNext, we will read the data provided by the Course Instructor into the R environment. We will use the read_csv() function from the readr package found in tidyverse.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\nglimpse(exam_data)\n\nRows: 322\nColumns: 7\n$ ID      &lt;chr&gt; \"Student321\", \"Student305\", \"Student289\", \"Student227\", \"Stude…\n$ CLASS   &lt;chr&gt; \"3I\", \"3I\", \"3H\", \"3F\", \"3I\", \"3I\", \"3I\", \"3I\", \"3I\", \"3H\", \"3…\n$ GENDER  &lt;chr&gt; \"Male\", \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Male\", \"M…\n$ RACE    &lt;chr&gt; \"Malay\", \"Malay\", \"Chinese\", \"Chinese\", \"Malay\", \"Malay\", \"Chi…\n$ ENGLISH &lt;dbl&gt; 21, 24, 26, 27, 27, 31, 31, 31, 33, 34, 34, 36, 36, 36, 37, 38…\n$ MATHS   &lt;dbl&gt; 9, 22, 16, 77, 11, 16, 21, 18, 19, 49, 39, 35, 23, 36, 49, 30,…\n$ SCIENCE &lt;dbl&gt; 15, 16, 16, 31, 25, 16, 25, 27, 15, 37, 42, 22, 32, 36, 35, 45…\n\n\nUsing glimpse to view the data, it is observed that the data contains the examination grades of a batch of primary 3 students for the subjects English, Maths, and Science."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#plotting-a-half-eye-graph",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#plotting-a-half-eye-graph",
    "title": "Hands-on Exercise 04 - Visualising Distributions",
    "section": "4.1. Plotting a Half Eye Graph",
    "text": "4.1. Plotting a Half Eye Graph\nThe first step to creating a raincloud plot is to create a half eye plot, which is half of a violin plot. This can be done using the stat_halfeye() function from the ggdist package. In this example, we plot English grades against Race.\n\nggplot(data = exam_data,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_color = NA) +\n  ggtitle(\"Half Eye Plot Is The First Step\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#adding-a-boxplot",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#adding-a-boxplot",
    "title": "Hands-on Exercise 04 - Visualising Distributions",
    "section": "4.2. Adding a Boxplot",
    "text": "4.2. Adding a Boxplot\nNext, we add a boxplot to the half eye plot using geom_boxplot().\n\nggplot(data = exam_data,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_color = NA) +\n  geom_boxplot(width = 0.1,\n               outlier.shape = NA) +\n  ggtitle(\"Next We Add A Boxplot\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#adding-a-half-dotplot",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#adding-a-half-dotplot",
    "title": "Hands-on Exercise 04 - Visualising Distributions",
    "section": "4.3. Adding a Half-Dotplot",
    "text": "4.3. Adding a Half-Dotplot\nThe third step requires use to add in the “raindrops” in the form of a dotplot. This can be done using the stat_dots() function of the ggdist package. This creates a half-dotplot:\n\nggplot(data = exam_data,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_color = NA) +\n  geom_boxplot(width = 0.1,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = 0.5,\n            dotsize = 2) +\n  ggtitle(\"Thirdly, We Add A Dotplot\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#let-it-rain-insights",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04.html#let-it-rain-insights",
    "title": "Hands-on Exercise 04 - Visualising Distributions",
    "section": "4.4. Let It Rain (Insights)",
    "text": "4.4. Let It Rain (Insights)\nLastly, we use the coord_flip() function to rotate the chart to complete the raincloud appearance.\n\nggplot(data = exam_data,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_color = NA) +\n  geom_boxplot(width = 0.1,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = 0.5,\n            dotsize = 2) +\n  coord_flip() +\n  theme_classic() +\n  ggtitle(\"Raincloud Plot\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "",
    "text": "In the second part of the fourth lesson, we learn to use the ggstatsplot package to create visual graphics with statistical information. We will first explore some techniques with the Exam dataset before applying them to the Toyota Corolla case study."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#getting-starting",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#getting-starting",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "2.1. Getting Starting",
    "text": "2.1. Getting Starting\n\n2.1.1. Installing and Loading Packages\nWe will use ggstatsplotin addition totidyverse for this exercise:\nThe packages to be used can be installed and loaded into the R environment using the p_load() function from the pacman package:\n\npacman::p_load(tidyverse, ggstatsplot)\n\n\n\n2.1.2. Import Data\nNext, we will read the data provided by the Course Instructor into the R environment. We will use the read_csv() function from the readr package found in tidyverse.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\nglimpse(exam_data)\n\nRows: 322\nColumns: 7\n$ ID      &lt;chr&gt; \"Student321\", \"Student305\", \"Student289\", \"Student227\", \"Stude…\n$ CLASS   &lt;chr&gt; \"3I\", \"3I\", \"3H\", \"3F\", \"3I\", \"3I\", \"3I\", \"3I\", \"3I\", \"3H\", \"3…\n$ GENDER  &lt;chr&gt; \"Male\", \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Male\", \"M…\n$ RACE    &lt;chr&gt; \"Malay\", \"Malay\", \"Chinese\", \"Chinese\", \"Malay\", \"Malay\", \"Chi…\n$ ENGLISH &lt;dbl&gt; 21, 24, 26, 27, 27, 31, 31, 31, 33, 34, 34, 36, 36, 36, 37, 38…\n$ MATHS   &lt;dbl&gt; 9, 22, 16, 77, 11, 16, 21, 18, 19, 49, 39, 35, 23, 36, 49, 30,…\n$ SCIENCE &lt;dbl&gt; 15, 16, 16, 31, 25, 16, 25, 27, 15, 37, 42, 22, 32, 36, 35, 45…\n\n\nUsing glimpse to view the data, it is observed that the data contains the examination grades of a batch of primary 3 students for the subjects English, Maths, and Science."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#one-sample-test-using-gghistostats",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#one-sample-test-using-gghistostats",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "2.2. One-Sample Test Using gghistostats()",
    "text": "2.2. One-Sample Test Using gghistostats()\nIn this example, we use gghistostats() to build a visual of a one-sample test on English score:\n\nset.seed(1234)\n\ngghistostats(data = exam_data,\n             x = ENGLISH, \n             type = \"bayes\",\n             test.value = 60,\n             xlab = \"English Score\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one hypothesis to the likelihood to another. It can be interpreted as a measure of the strength of evidence in favour of one theory among two competing theories."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#two-sample-mean-test-using-ggbetweenstats",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#two-sample-mean-test-using-ggbetweenstats",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "2.3. Two-Sample Mean Test Using ggbetweenstats()",
    "text": "2.3. Two-Sample Mean Test Using ggbetweenstats()\nIn this example, we use ggbetweenstats() to build a visual of a two-sample mean test of Maths score by gender:\n\nggbetweenstats(data = exam_data,\n               x = GENDER, \n               y = MATHS,\n               type = \"np\",\n               messages = FALSE)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#one-way-anova-test-using-ggbetweenstats",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#one-way-anova-test-using-ggbetweenstats",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "2.4. One-Way ANOVA Test Using ggbetweenstats()",
    "text": "2.4. One-Way ANOVA Test Using ggbetweenstats()\nIn this example, we use ggbetweenstats() to build a visual of a one-way ANOVA test of English score by race:\n\nggbetweenstats(data = exam_data,\n               x = RACE, \n               y = ENGLISH,\n               type = \"p\",\n               mean.ci = TRUE,\n               pairwise_comparisons = TRUE,\n               pairwise.display = \"s\",\n               p.adjust.method = \"fdr\",\n               messages = FALSE)\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n“ns” = only non-significant\n“s” = only significant\n“all” = everything"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#significant-test-of-correlation-using-ggscatterstats",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#significant-test-of-correlation-using-ggscatterstats",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "2.5. Significant Test of Correlation Using ggscatterstats()",
    "text": "2.5. Significant Test of Correlation Using ggscatterstats()\nIn this example, we use ggscatterstats() to build a visual of a significant test of correlation between Maths and English scores:\n\nggscatterstats(data = exam_data,\n               x = MATHS, \n               y = ENGLISH,\n               marginal = FALSE)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#significant-test-of-association-dependence-using-ggbarstats",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#significant-test-of-association-dependence-using-ggbarstats",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "2.6. Significant Test of Association (Dependence) Using ggbarstats()",
    "text": "2.6. Significant Test of Association (Dependence) Using ggbarstats()\nIn this example, we use ggbarstats() to build a visual of a significant test of association after binning maths scores into a 4-class variable:\n\nexam1 &lt;- exam_data %&gt;%\n  mutate(MATHS_bins = cut(MATHS,\n                          breaks = c(0,60,75,85,100)))\n\nggbarstats(data = exam1,\n               x = MATHS_bins, \n               y = GENDER)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#getting-starting-1",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#getting-starting-1",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "3.1. Getting Starting",
    "text": "3.1. Getting Starting\n\n3.1.1. Installing and Loading Packages\nWe will load additional packages to be used into the R environment using the p_load() function from the pacman package:\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n\n3.1.2. Import Data\nNext, we will read the data provided by the Course Instructor into the R environment. We will use the read_xls() function from the readxl package.\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\nglimpse(car_resale)\n\nRows: 1,436\nColumns: 38\n$ Id               &lt;dbl&gt; 81, 1, 2, 3, 4, 5, 6, 7, 8, 44, 45, 46, 47, 49, 51, 6…\n$ Model            &lt;chr&gt; \"TOYOTA Corolla 1.6 5drs 1 4/5-Doors\", \"TOYOTA Coroll…\n$ Price            &lt;dbl&gt; 18950, 13500, 13750, 13950, 14950, 13750, 12950, 1690…\n$ Age_08_04        &lt;dbl&gt; 25, 23, 23, 24, 26, 30, 32, 27, 30, 27, 22, 23, 27, 2…\n$ Mfg_Month        &lt;dbl&gt; 8, 10, 10, 9, 7, 3, 1, 6, 3, 6, 11, 10, 6, 11, 11, 11…\n$ Mfg_Year         &lt;dbl&gt; 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002,…\n$ KM               &lt;dbl&gt; 20019, 46986, 72937, 41711, 48000, 38500, 61000, 9461…\n$ Quarterly_Tax    &lt;dbl&gt; 100, 210, 210, 210, 210, 210, 210, 210, 210, 234, 234…\n$ Weight           &lt;dbl&gt; 1180, 1165, 1165, 1165, 1165, 1170, 1170, 1245, 1245,…\n$ Guarantee_Period &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…\n$ HP_Bin           &lt;chr&gt; \"100-120\", \"&lt; 100\", \"&lt; 100\", \"&lt; 100\", \"&lt; 100\", \"&lt; 100…\n$ CC_bin           &lt;chr&gt; \"1600\", \"&gt;1600\", \"&gt;1600\", \"&gt;1600\", \"&gt;1600\", \"&gt;1600\", …\n$ Doors            &lt;dbl&gt; 5, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 3, 3,…\n$ Gears            &lt;dbl&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,…\n$ Cylinders        &lt;dbl&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,…\n$ Fuel_Type        &lt;chr&gt; \"Petrol\", \"Diesel\", \"Diesel\", \"Diesel\", \"Diesel\", \"Di…\n$ Color            &lt;chr&gt; \"Blue\", \"Blue\", \"Silver\", \"Blue\", \"Black\", \"Black\", \"…\n$ Met_Color        &lt;dbl&gt; 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,…\n$ Automatic        &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Mfr_Guarantee    &lt;dbl&gt; 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,…\n$ BOVAG_Guarantee  &lt;dbl&gt; 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ ABS              &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Airbag_1         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Airbag_2         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Airco            &lt;dbl&gt; 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Automatic_airco  &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,…\n$ Boardcomputer    &lt;dbl&gt; 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ CD_Player        &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,…\n$ Central_Lock     &lt;dbl&gt; 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Powered_Windows  &lt;dbl&gt; 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Power_Steering   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Radio            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Mistlamps        &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Sport_Model      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,…\n$ Backseat_Divider &lt;dbl&gt; 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Metallic_Rim     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Radio_cassette   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Tow_Bar          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\nUsing glimpse to view the data, it is observed that the data contains the details, vehicle parts and price of Toyota Corolla cars."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#multiple-regression-model-using-lm",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#multiple-regression-model-using-lm",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "3.2. Multiple Regression Model using lm()",
    "text": "3.2. Multiple Regression Model using lm()\nWe calibrate a multiple linear regression model by using the lm() function from the Base Stats provided on R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n            data = car_resale)\n\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n3.2.1. Model Diagnostic: Check for Multicollinearity\nWe use the check_collinearity() function from the performance package to check for multicollinearity.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_col &lt;- check_collinearity(model)\nplot(check_col)\n\n\n\n\n\n\n3.2.2. Model Diagnostic: Check for Normality Assumption\nWe use the check_normality() function from the performance package to check for normality.\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + Weight + Guarantee_Period, \n             data = car_resale)\n\ncheck_n &lt;- check_normality(model1)\n\nplot(check_n)\n\n\n\n\n\n\n3.2.3. Model Diagnostic: Check Model for Homogeneity of Variances\nWe use the check_heteroscedasticity() function from the performance package to check for homogeneity of variances.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\n\nplot(check_h)\n\n\n\n\n\n\n3.2.4. Model Diagnostic: Complete Check\nWe use the check_model() function from the performance package to conduct a complete check.\n\ncheck_model(model1)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#visualising-regression-parameters",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_2.html#visualising-regression-parameters",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "3.3. Visualising Regression Parameters`",
    "text": "3.3. Visualising Regression Parameters`\n\nplot()ggcoefstats()\n\n\nWe use the plot() function from the see package to visualise the parameters of the regression model.\n\nplot(parameters((model1)))\n\n\n\n\n\n\nWe use the ggcoefstats() function from the ggstatsplot package to visualise the parameters of the regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_3.html",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_3.html",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "",
    "text": "In the third part of the fourth lesson, we learn to visualise uncertainty. In a previous exercise, visualisation of uncertainty was one using ggiraph interactive visualiation methods."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_3.html#installing-and-loading-packages",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_3.html#installing-and-loading-packages",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "2.1. Installing and Loading Packages",
    "text": "2.1. Installing and Loading Packages\nWe will use ggstatsplotin addition totidyverse for this exercise:\nWe will load the packages to be used into the R environment using the p_load() function from the pacman package:\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_3.html#import-data",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_3.html#import-data",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "2.2. Import Data",
    "text": "2.2. Import Data\nNext, we will read the data provided by the Course Instructor into the R environment. We will use the read_csv() function from the readr package found in tidyverse.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\nglimpse(exam_data)\n\nRows: 322\nColumns: 7\n$ ID      &lt;chr&gt; \"Student321\", \"Student305\", \"Student289\", \"Student227\", \"Stude…\n$ CLASS   &lt;chr&gt; \"3I\", \"3I\", \"3H\", \"3F\", \"3I\", \"3I\", \"3I\", \"3I\", \"3I\", \"3H\", \"3…\n$ GENDER  &lt;chr&gt; \"Male\", \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Male\", \"M…\n$ RACE    &lt;chr&gt; \"Malay\", \"Malay\", \"Chinese\", \"Chinese\", \"Malay\", \"Malay\", \"Chi…\n$ ENGLISH &lt;dbl&gt; 21, 24, 26, 27, 27, 31, 31, 31, 33, 34, 34, 36, 36, 36, 37, 38…\n$ MATHS   &lt;dbl&gt; 9, 22, 16, 77, 11, 16, 21, 18, 19, 49, 39, 35, 23, 36, 49, 30,…\n$ SCIENCE &lt;dbl&gt; 15, 16, 16, 31, 25, 16, 25, 27, 15, 37, 42, 22, 32, 36, 35, 45…\n\n\nUsing glimpse to view the data, it is observed that the data contains the examination grades of a batch of primary 3 students for the subjects English, Maths, and Science."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_3.html#plotting-standard-error-bars-of-point-estimates",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_3.html#plotting-standard-error-bars-of-point-estimates",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "3.1. Plotting Standard Error Bars of Point Estimates",
    "text": "3.1. Plotting Standard Error Bars of Point Estimates\nNext, we plot the standard error bars of mean maths score by race using the code below:\n\n\nCodes here\nggplot(data = sum_stat) +\n  geom_errorbar(aes(x = RACE,\n                    ymin = mean-se,\n                    ymax = mean+se),\n                width = 0.2,\n                color = \"black\",\n                alpha = 0.9,\n                size = 0.5) +\n  geom_point(aes(x = RACE,\n                 y = mean),\n             stat = \"identity\",\n             color = \"red\",\n             size = 1.5,\n             alpha = 1) +\n  ggtitle(\"Standard Error Of Mean Maths Score By Race\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_3.html#plotting-confidence-interval-of-point-estimates",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_3.html#plotting-confidence-interval-of-point-estimates",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "3.2. Plotting Confidence Interval of Point Estimates",
    "text": "3.2. Plotting Confidence Interval of Point Estimates\nNext, we plot the confidence interval of mean maths score by race.\n\n\nCodes here\nggplot(data = sum_stat) +\n  geom_errorbar(aes(x = reorder(RACE, -mean),\n                    ymin = mean-1.96*se,\n                    ymax = mean+1.96*se),\n                width = 0.2,\n                color = \"black\",\n                alpha = 0.9,\n                size = 0.5) +\n  geom_point(aes(x = RACE,\n                 y = mean),\n             stat = \"identity\",\n             color = \"red\",\n             size = 1.5,\n             alpha = 1) +\n  labs(x = \"Maths Score\",\n       title = \"95% Confidence Interval Of Mean Maths Score By Race\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_3.html#visualising-uncertainty-of-point-estimates-using-interactive-error-bars",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_3.html#visualising-uncertainty-of-point-estimates-using-interactive-error-bars",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "3.3. Visualising Uncertainty of Point Estimates Using Interactive Error Bars",
    "text": "3.3. Visualising Uncertainty of Point Estimates Using Interactive Error Bars\nNext, we plot an interactive graph for the 99% confidence interval of mean maths score by race.\n\n\nCodes here\nshared_df = SharedData$new(sum_stat)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(data = shared_df) +\n                   geom_errorbar(aes(x=reorder(RACE, -mean),\n                                     ymin=mean-2.58*se, \n                                     ymax=mean+2.58*se), \n                                 width=0.2, \n                                 colour=\"black\", \n                                 alpha=0.9, \n                                 size=0.5) +\n                    geom_point(aes(x=RACE, \n                                   y=mean, \n                                   text = paste(\"Race:\", `RACE`, \n                                                \"&lt;br&gt;N:\", `n`,\n                                                \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                                \"&lt;br&gt;95% CI:[\", \n                                                round((mean-2.58*se), digits = 2), \",\",\n                                                round((mean+2.58*se), digits = 2),\"]\")),\n                               stat=\"identity\", \n                               color=\"red\", \n                               size = 1.5, \n                               alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_classic() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_4.html",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_4.html",
    "title": "Hands-on Exercise 4 - Funnel Plots",
    "section": "",
    "text": "In the fourth part of the fourth lesson, we explore the use of funnel plots. A funnel plot is specially designed to conduct unbiased comparison between outlets, stores, or business entities."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_4.html#loading-required-library",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_4.html#loading-required-library",
    "title": "Hands-on Exercise 4 - Funnel Plots",
    "section": "2.1. Loading Required Library",
    "text": "2.1. Loading Required Library\nWe will use FunnelPlotR in this exercise in addition to tidyverse, ggplot2, knitr, and plotly:\n\nFunnelPlotR: to create funnel plots\n\n\npacman::p_load(tidyverse, ggplot2, knitr, \n               plotly, FunnelPlotR)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_4.html#import-data",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_4.html#import-data",
    "title": "Hands-on Exercise 4 - Funnel Plots",
    "section": "2.2. Import Data",
    "text": "2.2. Import Data\nNext, we will read the data provided by the Course Instructor into the R environment. For this exercise, we will use the COVID-19_DKI_Jakarta downloaded from the Open Data COVID-19 Provinski DKI Jakarta Portal. The data is in CSV format and we will load the data into the R environment using the read_csv() function from the readr package found in tidyverse.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\n\nglimpse(covid19)\n\nRows: 267\nColumns: 7\n$ `Sub-district ID` &lt;dbl&gt; 3172051003, 3173041007, 3175041005, 3175031003, 3175…\n$ City              &lt;fct&gt; JAKARTA UTARA, JAKARTA BARAT, JAKARTA TIMUR, JAKARTA…\n$ District          &lt;fct&gt; PADEMANGAN, TAMBORA, KRAMAT JATI, JATINEGARA, CIPAYU…\n$ `Sub-district`    &lt;fct&gt; ANCOL, ANGKE, BALE KAMBANG, BALI MESTER, BAMBU APUS,…\n$ Positive          &lt;dbl&gt; 1776, 1783, 2049, 827, 2866, 1828, 2541, 3608, 2012,…\n$ Recovered         &lt;dbl&gt; 1691, 1720, 1964, 797, 2792, 1757, 2433, 3445, 1937,…\n$ Death             &lt;dbl&gt; 26, 29, 31, 13, 27, 26, 37, 68, 38, 52, 72, 28, 25, …\n\n\nUsing glimpse, it is observed that the data contains the status on COVID-19 patients by the sub-districts in Indonesia."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_4.html#compute-basic-derived-fields",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_4.html#compute-basic-derived-fields",
    "title": "Hands-on Exercise 4 - Funnel Plots",
    "section": "4.1. Compute Basic Derived Fields",
    "text": "4.1. Compute Basic Derived Fields\nIn this method, we have to first derive the cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1 - rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, we compute fit.mean using weighted_mean().\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_4.html#calculate-lower-and-upper-limits-for-95-and-99-ci",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_4.html#calculate-lower-and-upper-limits-for-95-and-99-ci",
    "title": "Hands-on Exercise 4 - Funnel Plots",
    "section": "4.2. Calculate Lower and Upper Limits for 95% and 99% CI",
    "text": "4.2. Calculate Lower and Upper Limits for 95% and 99% CI\nNext, we use the following code to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_4.html#plotting-a-static-funnel-plot",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_4.html#plotting-a-static-funnel-plot",
    "title": "Hands-on Exercise 4 - Funnel Plots",
    "section": "4.3. Plotting A Static Funnel Plot",
    "text": "4.3. Plotting A Static Funnel Plot\nNext, we use ggplot2 functions to plot a static funnel plot.\n\n\nCodes here\np &lt;- ggplot(data = df, \n            aes(x = Positive, \n                y = rate)) +\n  geom_point(aes(label = `Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0, 0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative COVID-19 Cases\") +\n  xlab(\"Cumulative COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_classic() +\n  theme(plot.title = element_text(size = 12),\n        legend.position = c(0.91, 0.85), \n        legend.title = element_text(size = 7),\n        legend.text = element_text(size = 7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex04/hands_on_ex04_4.html#plotting-an-interactive-funnel-plot",
    "href": "hands_on_ex/hands_on_ex04/hands_on_ex04_4.html#plotting-an-interactive-funnel-plot",
    "title": "Hands-on Exercise 4 - Funnel Plots",
    "section": "4.4. Plotting An Interactive Funnel Plot",
    "text": "4.4. Plotting An Interactive Funnel Plot\nWe use the ggplotly() function from the plotly package to create an interactive funnel plot.\n\nfp_interact &lt;- ggplotly(p,\n                        tooltip = c(\"label\", \n                                    \"x\",\n                                    \"y\"))\n\nfp_interact"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.html",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.html",
    "title": "Hands-on Exercise 05 - Building Ternary Plot",
    "section": "",
    "text": "In the first part of the fifth lesson, we learn to plot ternary plots to display the distribution and variability of three-part composition data. The plot is displayed as a triangle with each side, representing one component, scaled from 0 t 1."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.html#installing-and-loading-packages",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.html#installing-and-loading-packages",
    "title": "Hands-on Exercise 05 - Building Ternary Plot",
    "section": "2.1. Installing and Loading Packages",
    "text": "2.1. Installing and Loading Packages\nWe will use the the ggtern package in addition to tidyverse and plotly for this exercise:\n\nggtern: ggplot2 extension designed to create ternary diagrams\n\nThe packages to be used can be installed and loaded into the R environment using the p_load() function from the pacman package:\n\npacman::p_load(tidyverse, plotly, ggtern)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05.html#import-data",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05.html#import-data",
    "title": "Hands-on Exercise 05 - Building Ternary Plot",
    "section": "2.2. Import Data",
    "text": "2.2. Import Data\nFor this exercise. we will use the Singapore Residents by Planning Area Subzone, Age Group, Sex, and Type of Dwelling, June 2000 - 2018 data set available on SingStat. We will use import a tidied version provided by the Course Instructor into the R environment via the read_csv() function from the readr package found in tidyverse.\n\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\")\nglimpse(pop_data)\n\nRows: 108,126\nColumns: 5\n$ PA         &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"An…\n$ SZ         &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo…\n$ AG         &lt;chr&gt; \"AGE0-4\", \"AGE0-4\", \"AGE0-4\", \"AGE0-4\", \"AGE0-4\", \"AGE0-4\",…\n$ Year       &lt;dbl&gt; 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2011, 2012,…\n$ Population &lt;dbl&gt; 290, 270, 260, 250, 260, 250, 200, 180, 290, 290, 270, 300,…\n\n\nUsing glimpse to view the data, it is observed that the data contains the Planning Area, Subzone, Age Group, Year, and Population.\nNext, we use the mutate() function from the dplyr package to aggregate the Age Group: Young, Active, and Old. This will form the three-part composition data in the ternary diagram.\n\nagegp_aggregated &lt;- pop_data %&gt;%\n  mutate('Year' = as.character(Year)) %&gt;%\n  spread(key = AG, value = Population) %&gt;%\n  mutate(Young = rowSums(.[4:8])) %&gt;%\n  mutate(Active = rowSums(.[9:16])) %&gt;%\n  mutate(Old = rowSums(.[17:21])) %&gt;%\n  mutate(Total = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018) %&gt;%\n  filter(Total &gt; 0)\n\nagegp_aggregated\n\n# A tibble: 234 × 25\n   PA         SZ       Year  `AGE0-4` `AGE05-9` `AGE10-14` `AGE15-19` `AGE20-24`\n   &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo … 2018       180       270        320        300        260\n 2 Ang Mo Kio Cheng S… 2018      1060      1080       1080       1260       1400\n 3 Ang Mo Kio Chong B… 2018       900       900       1030       1220       1380\n 4 Ang Mo Kio Kebun B… 2018       720       850       1010       1120       1230\n 5 Ang Mo Kio Sembawa… 2018       220       310        380        500        550\n 6 Ang Mo Kio Shangri… 2018       550       630        670        780        950\n 7 Ang Mo Kio Tagore   2018       260       340        430        500        640\n 8 Ang Mo Kio Townsvi… 2018       830       930        930        860       1020\n 9 Ang Mo Kio Yio Chu… 2018       160       160        220        260        350\n10 Ang Mo Kio Yio Chu… 2018       810      1070       1300       1450       1500\n# ℹ 224 more rows\n# ℹ 17 more variables: `AGE25-29` &lt;dbl&gt;, `AGE30-34` &lt;dbl&gt;, `AGE35-39` &lt;dbl&gt;,\n#   `AGE40-44` &lt;dbl&gt;, `AGE45-49` &lt;dbl&gt;, `AGE50-54` &lt;dbl&gt;, `AGE55-59` &lt;dbl&gt;,\n#   `AGE60-64` &lt;dbl&gt;, `AGE65-69` &lt;dbl&gt;, `AGE70-74` &lt;dbl&gt;, `AGE75-79` &lt;dbl&gt;,\n#   `AGE80-84` &lt;dbl&gt;, AGE85over &lt;dbl&gt;, Young &lt;dbl&gt;, Active &lt;dbl&gt;, Old &lt;dbl&gt;,\n#   Total &lt;dbl&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nspread(): used to ‘spread’ a key-value pair across multiple columns.\nkey: column from original data whose values will become variable names\nvalue: column from original data whose values will fill under new variables created from key\n\nIn this example, each age group forms a new column and the corresponding population size is filled into the respective columns."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html",
    "title": "Hands-on Exercise 05 - Visual Correlation Analysis",
    "section": "",
    "text": "Correlation coefficient is a statistic used to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges from -1.0 to 1.0 - a correlation coefficient of 1 shows a perfect positive correlation, a correlation coefficient of -1 shows a perfect negative correlation, and a correlation coefficient of 0 shows no linear relationship.\nWhen multivariate data is used, we can display pair-wise comparisons of the correlation coefficient as a correlation matrix or a scatterplot matrix. This helps to reveal the relationship between high-dimensional variables, to be included into other analyses, and to use as a diagnostic tool such as testing for multi-collinearity.\nIn this exercise, we will visualise correlation matrix use pairs() and the corrplot package."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#installing-and-loading-packages",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#installing-and-loading-packages",
    "title": "Hands-on Exercise 05 - Visual Correlation Analysis",
    "section": "2.1. Installing and Loading Packages",
    "text": "2.1. Installing and Loading Packages\nWe will use the following R packages in addition to tidyverse for this exercise:\n\nggststplot: ggplot2 extension designed for creating graphics with details from statistical tsts\ncorrplot: to create correlation matrix\n\nThe packages to be used can be installed and loaded into the R environment using the p_load() function from the pacman package:\n\npacman::p_load(tidyverse, ggstatsplot, corrplot)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#import-data",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#import-data",
    "title": "Hands-on Exercise 05 - Visual Correlation Analysis",
    "section": "2.2. Import Data",
    "text": "2.2. Import Data\nNext, we will read the data provided by the Course Instructor into the R environment. We will use the read_csv() function from the readr package found in tidyverse.\n\nwine &lt;- read_csv('data/wine_quality.csv')\n\nglimpse(wine)\n\nRows: 6,497\nColumns: 13\n$ `fixed acidity`        &lt;dbl&gt; 7.4, 7.8, 7.8, 11.2, 7.4, 7.4, 7.9, 7.3, 7.8, 7…\n$ `volatile acidity`     &lt;dbl&gt; 0.700, 0.880, 0.760, 0.280, 0.700, 0.660, 0.600…\n$ `citric acid`          &lt;dbl&gt; 0.00, 0.00, 0.04, 0.56, 0.00, 0.00, 0.06, 0.00,…\n$ `residual sugar`       &lt;dbl&gt; 1.9, 2.6, 2.3, 1.9, 1.9, 1.8, 1.6, 1.2, 2.0, 6.…\n$ chlorides              &lt;dbl&gt; 0.076, 0.098, 0.092, 0.075, 0.076, 0.075, 0.069…\n$ `free sulfur dioxide`  &lt;dbl&gt; 11, 25, 15, 17, 11, 13, 15, 15, 9, 17, 15, 17, …\n$ `total sulfur dioxide` &lt;dbl&gt; 34, 67, 54, 60, 34, 40, 59, 21, 18, 102, 65, 10…\n$ density                &lt;dbl&gt; 0.9978, 0.9968, 0.9970, 0.9980, 0.9978, 0.9978,…\n$ pH                     &lt;dbl&gt; 3.51, 3.20, 3.26, 3.16, 3.51, 3.51, 3.30, 3.39,…\n$ sulphates              &lt;dbl&gt; 0.56, 0.68, 0.65, 0.58, 0.56, 0.56, 0.46, 0.47,…\n$ alcohol                &lt;dbl&gt; 9.4, 9.8, 9.8, 9.8, 9.4, 9.4, 9.4, 10.0, 9.5, 1…\n$ quality                &lt;dbl&gt; 5, 5, 5, 6, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5,…\n$ type                   &lt;chr&gt; \"red\", \"red\", \"red\", \"red\", \"red\", \"red\", \"red\"…\n\n\nUsing glimpse to view the data, it is observed that the data contains 13 variables and 6497 observations of wine attributes and quality of red and white wine."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#basic-correlation-matrix",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#basic-correlation-matrix",
    "title": "Hands-on Exercise 05 - Visual Correlation Analysis",
    "section": "3.1. Basic Correlation Matrix",
    "text": "3.1. Basic Correlation Matrix\n\npairs(wine[,2:11])"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#customisation",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#customisation",
    "title": "Hands-on Exercise 05 - Visual Correlation Analysis",
    "section": "3.2. Customisation",
    "text": "3.2. Customisation\n\n3.2.1. Drawing One Corner\nThe pairs() function provides customisation arguments to show either the upper ror lower half of the correlation matrix.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n3.2.2. Including Correlation Coefficient\nWe can use the `panel.cor function to include the correlation coefficient into the correlation matrix.\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#basic-corrgram",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#basic-corrgram",
    "title": "Hands-on Exercise 05 - Visual Correlation Analysis",
    "section": "4.1. Basic Corrgram",
    "text": "4.1. Basic Corrgram\nWe will use the ggcormat() function to create a scatterplot matrix.\n\nggcorrmat(data = wine,\n          cor.vars = 1:11,\n          ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n          title    = \"Correlogram for wine dataset\",\n          subtitle = \"Four pairs are no significant at p &lt; 0.05\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#visual-geometrics",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#visual-geometrics",
    "title": "Hands-on Exercise 05 - Visual Correlation Analysis",
    "section": "6.1.Visual Geometrics",
    "text": "6.1.Visual Geometrics\nIn the corrplot() package, there are seven visual geometrics to encode the attribute values: circle, square, ellipse, number, shade, color, and pie, We can change the geometrics using the following code:\n\ncorrplot(wine.cor, \n         method = 'number')"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#layout",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#layout",
    "title": "Hands-on Exercise 05 - Visual Correlation Analysis",
    "section": "6.2. Layout",
    "text": "6.2. Layout\nThe corrplot() package supports three layout types: full, upper, or lower.\n\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         type = \"upper\",\n         diag = FALSE,\n         tl.col = \"black\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#mixed-layout",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#mixed-layout",
    "title": "Hands-on Exercise 05 - Visual Correlation Analysis",
    "section": "6.3. Mixed Layout",
    "text": "6.3. Mixed Layout\nThe corrplot() function allows for customisations to mix the visual matrix with half visual matrix and half numerical matrix. We can use the corrplot.mixed() function to achieve this.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#significant-test",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#significant-test",
    "title": "Hands-on Exercise 05 - Visual Correlation Analysis",
    "section": "6.4. Significant Test",
    "text": "6.4. Significant Test\nWe can use the cor.mtest() function to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level = 0.95)\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = 0.05)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#reorder-a-corrgram",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_2.html#reorder-a-corrgram",
    "title": "Hands-on Exercise 05 - Visual Correlation Analysis",
    "section": "6.5. Reorder a Corrgram",
    "text": "6.5. Reorder a Corrgram\ncorrplot() supports four sorting methods:\n\n“AOE” for the angular order of the eigenvectors\n“FPC” for the first principal component order\n“hclust” for hierarchical clustering order and “hclust.method” for the agglomeration method where a definiion must be provided: “ward”, “single”, “complete”, “average”, “mcquitty”, “median”, or “centroid”\n“alphabet” for alphabetical order\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\nWe can use the hclust() method to reorder the correlation matrix:\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_3.html",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_3.html",
    "title": "Hands-on Exercise 05 - Multivariate Analysis with Heatmap",
    "section": "",
    "text": "In the third part of the fifth lesson, we learn to visualise multivariate data using heatmaps. Heatmaps show variance across multiple variables and reveal patterns about the data."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_3.html#installing-and-loading-packages",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_3.html#installing-and-loading-packages",
    "title": "Hands-on Exercise 05 - Multivariate Analysis with Heatmap",
    "section": "2.1. Installing and Loading Packages",
    "text": "2.1. Installing and Loading Packages\nWe will use the following R packages in addition to tidyverse for this exercise:\n\nseriation: infrastructure for ordering objects such as matrices, dissimiliarity matrices, and dendograms\nheatmaply: to create heatmaps\ndendextend: function for extending dendogram objects on R\n\nThe packages to be used can be installed and loaded into the R environment using the p_load() function from the pacman package:\n\npacman::p_load(tidyverse, seriation, heatmaply,\n               dendextend)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_3.html#import-data",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_3.html#import-data",
    "title": "Hands-on Exercise 05 - Multivariate Analysis with Heatmap",
    "section": "2.2. Import Data",
    "text": "2.2. Import Data\nNext, we will read the data provided by the Course Instructor into the R environment. We will use the read_csv() function from the readr package found in tidyverse.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\nglimpse(wh)\n\nRows: 156\nColumns: 12\n$ Country                        &lt;chr&gt; \"Albania\", \"Bosnia and Herzegovina\", \"B…\n$ Region                         &lt;chr&gt; \"Central and Eastern Europe\", \"Central …\n$ `Happiness score`              &lt;dbl&gt; 4.586, 5.129, 4.933, 5.321, 6.711, 5.73…\n$ `Whisker-high`                 &lt;dbl&gt; 4.695, 5.224, 5.022, 5.398, 6.783, 5.81…\n$ `Whisker-low`                  &lt;dbl&gt; 4.477, 5.035, 4.844, 5.244, 6.639, 5.66…\n$ Dystopia                       &lt;dbl&gt; 1.462, 1.883, 1.219, 1.769, 2.494, 1.45…\n$ `GDP per capita`               &lt;dbl&gt; 0.916, 0.915, 1.054, 1.115, 1.233, 1.20…\n$ `Social support`               &lt;dbl&gt; 0.817, 1.078, 1.515, 1.161, 1.489, 1.53…\n$ `Healthy life expectancy`      &lt;dbl&gt; 0.790, 0.758, 0.712, 0.737, 0.854, 0.73…\n$ `Freedom to make life choices` &lt;dbl&gt; 0.419, 0.280, 0.359, 0.380, 0.543, 0.55…\n$ Generosity                     &lt;dbl&gt; 0.149, 0.216, 0.064, 0.120, 0.064, 0.08…\n$ `Perceptions of corruption`    &lt;dbl&gt; 0.032, 0.000, 0.009, 0.039, 0.034, 0.17…\n\n\nUsing glimpse to view the data, it is observed that the data contains the happiness index in 12 columns and 156 observations."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_3.html#data-preparation",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_3.html#data-preparation",
    "title": "Hands-on Exercise 05 - Multivariate Analysis with Heatmap",
    "section": "2.3. Data Preparation",
    "text": "2.3. Data Preparation\nWe prepare the data by arranging the rows according to country name instead of row number.\n\nrow.names(wh) &lt;- wh$Country\n\nNext, we transform the data frame into a matrix before we can create a heatmap.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_3.html#data-transformation",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_3.html#data-transformation",
    "title": "Hands-on Exercise 05 - Multivariate Analysis with Heatmap",
    "section": "4.1. Data Transformation",
    "text": "4.1. Data Transformation\nThere are three main data transformation methods supported by heatmaply() top transform data using a common scale for comparison: scale, normalise, percentise.\n\nScaleNormalisePercentise\n\n\nWhen all variables are from or assumed to be from a normal distribution, scaling would bring all the values close to the standard normal distribution. After scaling, the value would reflect the number of standard deviations away from the mean.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\nWhen the variables in the data are from possibly different distributions, the normalise function can be used to bring the data onto a common 0.00 to 1.00 scale. This preserves the shape of each variable’s distribution while making them comparable on the same scale.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\nThe variables are ranked and each rank received is divided by the maximum rank to obtain a percentage. This provides clear interpretation as each value reflects the percentage of observations that received less than or equal to its own value.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_3.html#clustering-algorithm",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_3.html#clustering-algorithm",
    "title": "Hands-on Exercise 05 - Multivariate Analysis with Heatmap",
    "section": "4.2. Clustering Algorithm",
    "text": "4.2. Clustering Algorithm\nheatmaply() supports different hierarchical clustering algorithms through the following arguments:\n\ndistfun: computes the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used foruse correlation-based clustering.\nhclustfun: used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method: default is NULL, which uses “euclidean”. Alternative methods include: “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method: default is NULL, which uses “complete” method. Alternative methods include: “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nA clustering model can be calibrated manually or statistically. We explore both options below:\n\nManuallyStatistical\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\nFirst, we determine the best clustering method and the number of clusters using the dend_expend() and find_k() functions from the dendextend package:\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nFrom the output, we can tell that the “average” method should be used as it gave the highest optimum value.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nFrom the graph, we can tell that having 3 clusters would give us optimal results\nHence, we can plot the heatmap accordingly:\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_4.html",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_4.html",
    "title": "Hands-on Exercise 05 - Multivariate Analysis with Parallel Coordinates Plot",
    "section": "",
    "text": "In the fourth part of the fifth lesson, we learn to visualise multivariate, numerical datau sing parallel coordinates plots. It is ideal for comparing multiple variables and seeing relationships between them. It can be used to characterise clusters that are detected during customer segmentation."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_4.html#installing-and-loading-packages",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_4.html#installing-and-loading-packages",
    "title": "Hands-on Exercise 05 - Multivariate Analysis with Parallel Coordinates Plot",
    "section": "2.1. Installing and Loading Packages",
    "text": "2.1. Installing and Loading Packages\nWe will load the following R packages for this exercise using the p_load() function from the pacman package:\n\npacman::p_load(tidyverse, GGally, parallelPlot)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_4.html#import-data",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_4.html#import-data",
    "title": "Hands-on Exercise 05 - Multivariate Analysis with Parallel Coordinates Plot",
    "section": "2.2. Import Data",
    "text": "2.2. Import Data\nNext, we will read the data provided by the Course Instructor into the R environment. We will use the read_csv() function from the readr package found in tidyverse.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\nglimpse(wh)\n\nRows: 156\nColumns: 12\n$ Country                        &lt;chr&gt; \"Albania\", \"Bosnia and Herzegovina\", \"B…\n$ Region                         &lt;chr&gt; \"Central and Eastern Europe\", \"Central …\n$ `Happiness score`              &lt;dbl&gt; 4.586, 5.129, 4.933, 5.321, 6.711, 5.73…\n$ `Whisker-high`                 &lt;dbl&gt; 4.695, 5.224, 5.022, 5.398, 6.783, 5.81…\n$ `Whisker-low`                  &lt;dbl&gt; 4.477, 5.035, 4.844, 5.244, 6.639, 5.66…\n$ Dystopia                       &lt;dbl&gt; 1.462, 1.883, 1.219, 1.769, 2.494, 1.45…\n$ `GDP per capita`               &lt;dbl&gt; 0.916, 0.915, 1.054, 1.115, 1.233, 1.20…\n$ `Social support`               &lt;dbl&gt; 0.817, 1.078, 1.515, 1.161, 1.489, 1.53…\n$ `Healthy life expectancy`      &lt;dbl&gt; 0.790, 0.758, 0.712, 0.737, 0.854, 0.73…\n$ `Freedom to make life choices` &lt;dbl&gt; 0.419, 0.280, 0.359, 0.380, 0.543, 0.55…\n$ Generosity                     &lt;dbl&gt; 0.149, 0.216, 0.064, 0.120, 0.064, 0.08…\n$ `Perceptions of corruption`    &lt;dbl&gt; 0.032, 0.000, 0.009, 0.039, 0.034, 0.17…\n\n\nUsing glimpse to view the data, it is observed that the data contains the happiness index in 12 columns and 156 observations."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html",
    "title": "Hands-on Exercise 5 - Treemap Visualisation",
    "section": "",
    "text": "In the final part of the fifth lesson, we learn to create treemap visualisations using R."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html#installing-and-loading-packages",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html#installing-and-loading-packages",
    "title": "Hands-on Exercise 5 - Treemap Visualisation",
    "section": "2.1. Installing and Loading Packages",
    "text": "2.1. Installing and Loading Packages\nWe will load the following R packages for this exercise using the p_load() function from the pacman package:\n\npacman::p_load(tidyverse, treemap, treemapify)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html#import-data",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html#import-data",
    "title": "Hands-on Exercise 5 - Treemap Visualisation",
    "section": "2.2. Import Data",
    "text": "2.2. Import Data\nNext, we will read the realis2018.csv data extracted from Urban Redevelopment Authority’s Real Estate Information System (REALIS). We will use the read_csv() function from the readr package found in tidyverse.\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\nglimpse(realis2018)\n\nRows: 23,205\nColumns: 20\n$ `Project Name`                &lt;chr&gt; \"ADANA @ THOMSON\", \"ALANA\", \"ALANA\", \"AL…\n$ Address                       &lt;chr&gt; \"8 Old Upper Thomson Road  #05-03\", \"156…\n$ `No. of Units`                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ `Area (sqm)`                  &lt;dbl&gt; 52, 284, 256, 256, 277, 285, 234, 155, 1…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Transacted Price ($)`        &lt;dbl&gt; 888888, 2530000, 2390863, 2450000, 19800…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"2382517\", \"2441654\", \"-\", \"-\"…\n$ `Unit Price ($ psm)`          &lt;dbl&gt; 17094, 8908, 9307, 9538, 7148, 6947, 147…\n$ `Unit Price ($ psf)`          &lt;dbl&gt; 1588, 828, 865, 886, 664, 645, 1371, 149…\n$ `Sale Date`                   &lt;chr&gt; \"4-Jul-18\", \"5-Oct-18\", \"9-Jun-18\", \"14-…\n$ `Property Type`               &lt;chr&gt; \"Apartment\", \"Terrace House\", \"Terrace H…\n$ Tenure                        &lt;chr&gt; \"Freehold\", \"103 Yrs From 12/08/2013\", \"…\n$ `Completion Date`             &lt;chr&gt; \"2018\", \"2018\", \"2018\", \"2018\", \"2008\", …\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"Sub Sale\", \"New Sale\", \"New…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"Private\", \"Private\", \"HDB\", \"N.A\", \"Pri…\n$ `Postal District`             &lt;dbl&gt; 20, 28, 28, 28, 26, 26, 26, 26, 26, 26, …\n$ `Postal Sector`               &lt;dbl&gt; 57, 80, 80, 80, 78, 78, 78, 78, 78, 78, …\n$ `Postal Code`                 &lt;dbl&gt; 573868, 804555, 804529, 804540, 786300, …\n$ `Planning Region`             &lt;chr&gt; \"North East Region\", \"North East Region\"…\n$ `Planning Area`               &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\"…\n\n\nUsing glimpse to view the data, it is observed that the data contains the real estate information pf public and private property from 2018. The data contains 20 columns and 23205 observations."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html#data-wrangling-and-manipulation",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html#data-wrangling-and-manipulation",
    "title": "Hands-on Exercise 5 - Treemap Visualisation",
    "section": "2.3. Data Wrangling and Manipulation",
    "text": "2.3. Data Wrangling and Manipulation\nThe current data frame is highly disaggregated as it includes records at the transaction level. The following data wrangling steps have to be taken to create a dataframe appropriate for treemap visualisation:\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type, and Type of Sale\nCompute new columns containing Total Unit Sold, Total Area, Median Unit Price, and Median Transacted Price by applying summary statistics functions on No. of Units, Area (sqm), Unit Price ($ sqm), and Transacted Price ($) respectively.\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html#static-treemap",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html#static-treemap",
    "title": "Hands-on Exercise 5 - Treemap Visualisation",
    "section": "3.1. Static Treemap",
    "text": "3.1. Static Treemap\nWe use the treemap() function from the treemap package to plot a treemap to show the distribution of resale condominiums using median unit prices and total unit sold by geographic hierarchy in 2018:\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"), \n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2018\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nindex argument must have at least two column names to create a hierarchy treemap. Aggregation is done in order of column names defined in the code.\nvSize argument must not contain negative values as it is used to map the size of rectangles of the treemap.\nvColor argument is used together with type argument to determine the colours of the rectangles. When undefined, type = index is used by default, which results in the colours assigned by planning region instead of by median unit price.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2018\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nWhen type = value is defined, the intensity of colours assigned to each rectangle corresponds to the value of the Median Unit Price.\n\ntype = valuetype = manual\n\n\nWhen type = value is defined, the colour palettes are considered to be diverging and colours are mapped such that 0 corresponds to the colour in the middle.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2018\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\nWhen type = manual is defined, the colours are mapped such that min value takes the left-end colour while max value takes the right-end colour, and mean value takes the middle colour.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdBu\", \n        title=\"Resale Condominium by Planning Region and Area, 201\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nDiverging colours do not work well in this case as all the median unit price values are positive numbers. In this case, we should use a single colour palette where intensitiy of colour corresponds to the value of median price:\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2018\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html#treemap-layout",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html#treemap-layout",
    "title": "Hands-on Exercise 5 - Treemap Visualisation",
    "section": "3.2. Treemap Layout",
    "text": "3.2. Treemap Layout\ntreemap() supports two popular treemap layouts, “squarified” and “pivotSize” (default). The layout can be adjusted using the algorithm argument.\n\nalgorithm = \"squarified\"algorithm = \"pivotSize\" With SortID\n\n\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2018\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nThe squarified algorithm produces good aspect ratios but ignores the sorting order of the rectangles.\n\n\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2018\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nWhen algorithm = \"pivotSize\" is defined, the sortID argument can be used to determine the order of rectangles to be places from top left to bottom right. In this case, sorting order is taken into account while aspect rations remain acceptable."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html#basic-treemap",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html#basic-treemap",
    "title": "Hands-on Exercise 5 - Treemap Visualisation",
    "section": "4.1. Basic Treemap",
    "text": "4.1. Basic Treemap\n\nggplot(data = realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html#define-hierarchy",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html#define-hierarchy",
    "title": "Hands-on Exercise 5 - Treemap Visualisation",
    "section": "4.2. Define Hierarchy",
    "text": "4.2. Define Hierarchy\n\nPlanning RegionPlanning AreaAdd Boundary Line\n\n\n\nggplot(data = realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(color = \"grey50\",\n                                size = 2) +\n  geom_treemap_subgroup_border(color = 'grey40') +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html#creating-an-interactive-treemap",
    "href": "hands_on_ex/hands_on_ex05/hands_on_ex05_5.html#creating-an-interactive-treemap",
    "title": "Hands-on Exercise 5 - Treemap Visualisation",
    "section": "5.1. Creating an Interactive Treemap",
    "text": "5.1. Creating an Interactive Treemap\nFirst, we have to build a treemap and store it as an object:\n\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2018\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nNext, we use the d3tree() function to make the treemap interactive:\n\nd3tree(tm,rootname = \"Singapore\" )\n\n\n\n\n\nWe can zoom into each region by clicking on any of its rectangles."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html",
    "title": "Hands-on Exercise 06 - Time-Oriented Data",
    "section": "",
    "text": "In the sixth lesson, we learn to visualise and analyse time-oriented data such as calendar heatmap, cyclce plot, slopeplot, and a horizon chart."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#installing-and-loading-packages",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#installing-and-loading-packages",
    "title": "Hands-on Exercise 06 - Time-Oriented Data",
    "section": "2.1. Installing and Loading Packages",
    "text": "2.1. Installing and Loading Packages\nWe will use the following R packages for this exercise:\n\npacman::p_load(tidyverse, readxl, data.table,\n               ggthemes, scales, viridis, \n               knitr, lubridate, gridExtra, CGPfunctions)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#import-data",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#import-data",
    "title": "Hands-on Exercise 06 - Time-Oriented Data",
    "section": "3.1. Import Data",
    "text": "3.1. Import Data\nWe will read the dataset on cyber attack records provided by the Course Instructor into the R environment. We will use the read_csv() function from the readr package found in tidyverse.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nUsing kable() from the knitr packaage to view the data, it is observed that the data contains three columns:\n\ntimestamp: datetime values in POSIXct format\nsource_country: source of cyber attack following ISO 3166-1 alpha-2 country code\ntz: timezone of the source IP address."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#data-preparation",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#data-preparation",
    "title": "Hands-on Exercise 06 - Time-Oriented Data",
    "section": "3.2. Data Preparation",
    "text": "3.2. Data Preparation\nFirst, w write the following function to derive the weekday and hour of day fields to be used later in the calendar heatmap:\n\nhr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   weekday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#basic-calendar-heatmap",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#basic-calendar-heatmap",
    "title": "Hands-on Exercise 06 - Time-Oriented Data",
    "section": "3.3. Basic Calendar Heatmap",
    "text": "3.3. Basic Calendar Heatmap\nNext, we derive a tibble data frame containing cyber attacks grouped by source country time zone.\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', 'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(weekday = factor(\n    weekday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nweekday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\nLastly, we create the plot:\n\ngrouped &lt;- attacks %&gt;% \n  count(weekday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           weekday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"thistle1\", \n                    high = \"red3\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by day of week and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#multiple-calendar-heatmaps",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#multiple-calendar-heatmaps",
    "title": "Hands-on Exercise 06 - Time-Oriented Data",
    "section": "3.4. Multiple Calendar Heatmaps",
    "text": "3.4. Multiple Calendar Heatmaps\nWe can plot multiple calendar heatmaps with the top four source countries of cyber attacks.\nFirst, we have to derive an object containing the count of attacks by source country:\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nNext, we prepare the tibble data frame containing the attack records of the top four source countries:\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\n\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, weekday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\nLastly, we create the plot:\n\nggplot(top4_attacks, \n       aes(hour, \n           weekday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"thistle1\", \n                    high = \"red3\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by day of week and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#import-data-1",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#import-data-1",
    "title": "Hands-on Exercise 06 - Time-Oriented Data",
    "section": "4.1. Import Data",
    "text": "4.1. Import Data\nWe will read the dataset on visitor arrivals from Vietnam provided by the Course Instructor into the R environment. We will use the read_excel() function from the readxl package.\n\narrive_air &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\nglimpse(arrive_air)\n\nRows: 240\nColumns: 36\n$ `Month-Year`               &lt;dttm&gt; 2000-01-01, 2000-02-01, 2000-03-01, 2000-0…\n$ `Republic of South Africa` &lt;dbl&gt; 3291, 2357, 4036, 4241, 2841, 2776, 3728, 2…\n$ Canada                     &lt;dbl&gt; 5545, 6120, 6255, 4521, 3914, 3487, 4238, 4…\n$ USA                        &lt;dbl&gt; 25906, 28262, 30439, 25378, 26163, 28179, 2…\n$ Bangladesh                 &lt;dbl&gt; 2883, 2469, 2904, 2843, 2793, 3146, 3489, 3…\n$ Brunei                     &lt;dbl&gt; 3749, 3236, 3342, 5117, 4152, 5018, 5026, 6…\n$ China                      &lt;dbl&gt; 33895, 34344, 27053, 30464, 30775, 26720, 3…\n$ `Hong Kong SAR (China)`    &lt;dbl&gt; 13692, 19870, 17086, 22346, 16357, 18133, 2…\n$ India                      &lt;dbl&gt; 19235, 18975, 21049, 26160, 35869, 31314, 2…\n$ Indonesia                  &lt;dbl&gt; 65151, 37105, 44205, 45480, 38350, 47982, 5…\n$ Japan                      &lt;dbl&gt; 59288, 58188, 74426, 49985, 48937, 53798, 6…\n$ `South Korea`              &lt;dbl&gt; 21457, 19634, 20719, 17489, 19398, 17522, 2…\n$ Kuwait                     &lt;dbl&gt; 507, 199, 386, 221, 164, 440, 1943, 2694, 4…\n$ Malaysia                   &lt;dbl&gt; 27472, 29084, 30504, 34478, 34795, 34660, 2…\n$ Myanmar                    &lt;dbl&gt; 1177, 1161, 1355, 1593, 1397, 1715, 1354, 1…\n$ Pakistan                   &lt;dbl&gt; 2150, 2496, 2429, 2711, 2594, 2924, 4001, 3…\n$ Philippines                &lt;dbl&gt; 8404, 9128, 11691, 14141, 13305, 10555, 968…\n$ `Saudi Arabia`             &lt;dbl&gt; 1312, 623, 1578, 705, 679, 2749, 5748, 4012…\n$ `Sri Lanka`                &lt;dbl&gt; 3922, 3988, 4259, 6579, 4625, 4740, 4764, 5…\n$ Taiwan                     &lt;dbl&gt; 15766, 24861, 18767, 22735, 18399, 21042, 2…\n$ Thailand                   &lt;dbl&gt; 12048, 12745, 16971, 20397, 15769, 17217, 1…\n$ `United Arab Emirates`     &lt;dbl&gt; 1318, 899, 1474, 1284, 1042, 1545, 3641, 33…\n$ Vietnam                    &lt;dbl&gt; 1527, 2269, 2034, 2420, 1833, 2480, 2221, 2…\n$ `Belgium & Luxembourg`     &lt;dbl&gt; 1434, 1596, 1548, 1592, 1167, 1170, 1912, 1…\n$ CIS                        &lt;dbl&gt; 2703, 1182, 1088, 1012, 660, 712, 911, 864,…\n$ Finland                    &lt;dbl&gt; 1634, 1297, 1220, 1208, 743, 982, 680, 1029…\n$ France                     &lt;dbl&gt; 4752, 6391, 5528, 5544, 4225, 4047, 5769, 6…\n$ Germany                    &lt;dbl&gt; 12739, 13093, 13645, 13366, 10878, 9054, 10…\n$ Ireland                    &lt;dbl&gt; 1292, 1200, 1368, 1345, 1067, 1363, 1348, 1…\n$ Italy                      &lt;dbl&gt; 3544, 2897, 2717, 2512, 2205, 2196, 2988, 6…\n$ Netherlands                &lt;dbl&gt; 4962, 5054, 4950, 4149, 3643, 3544, 5969, 5…\n$ Spain                      &lt;dbl&gt; 925, 747, 935, 941, 764, 855, 1163, 1669, 1…\n$ Switzerland                &lt;dbl&gt; 3731, 3980, 3576, 3850, 3025, 2580, 3656, 2…\n$ `United Kingdom`           &lt;dbl&gt; 28986, 35148, 36117, 33792, 23377, 21769, 2…\n$ Australia                  &lt;dbl&gt; 34616, 26030, 31119, 34824, 33139, 35731, 4…\n$ `New Zealand`              &lt;dbl&gt; 5034, 3938, 4668, 6890, 7006, 7634, 9502, 6…\n\n\nUsing glimpse() to view the data, it is observed that the data contains 36 columns and 240 observations."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#data-preparation-1",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#data-preparation-1",
    "title": "Hands-on Exercise 06 - Time-Oriented Data",
    "section": "4.2. Data Preparation",
    "text": "4.2. Data Preparation\nFirst, we create two new columns “month” and “year” from the “Month-Year” field:\n\narrive_air$month &lt;- factor(month(arrive_air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \narrive_air$year &lt;- year(ymd(arrive_air$`Month-Year`))\n\nWe now extract the data for this study, which is arrivals from Vietnam:\n\nvietnam &lt;- arrive_air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\nglimpse(vietnam)\n\nRows: 120\nColumns: 3\n$ Vietnam &lt;dbl&gt; 15781, 16335, 18061, 22154, 21461, 28146, 34020, 25351, 20105,…\n$ month   &lt;ord&gt; Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec, Ja…\n$ year    &lt;int&gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 20…\n\n\nNext, we compute the yearly average arrival numbers, grouped by month:\n\nhline.data &lt;- vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`vietnam`))"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#create-cycle-plot",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#create-cycle-plot",
    "title": "Hands-on Exercise 06 - Time-Oriented Data",
    "section": "4.3. Create Cycle Plot",
    "text": "4.3. Create Cycle Plot\nLastly, we create the plot:\n\nggplot() + \n  geom_line(data = vietnam,\n            aes(x = year, \n                y = Vietnam, \n                group = month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#import-data-2",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#import-data-2",
    "title": "Hands-on Exercise 06 - Time-Oriented Data",
    "section": "5.1. Import Data",
    "text": "5.1. Import Data\nWe will read the dataset on rice yied provided by the Course Instructor into the R environment. We will use the read_csv() function from the readr package found in tidyverse.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\nglimpse(rice)\n\nRows: 550\nColumns: 4\n$ Country    &lt;chr&gt; \"China\", \"China\", \"China\", \"China\", \"China\", \"China\", \"Chin…\n$ Year       &lt;dbl&gt; 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970,…\n$ Yield      &lt;dbl&gt; 20787, 23700, 26833, 28289, 29667, 31445, 31006, 31868, 314…\n$ Production &lt;dbl&gt; 56217601, 65675288, 76439280, 85853780, 90705630, 98403990,…\n\n\nUsing glimpse() to view the data, it is observed that the data contains four columns and 550 records on the yield of rice by year and country."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#create-slopegraph",
    "href": "hands_on_ex/hands_on_ex06/hands_on_ex06.html#create-slopegraph",
    "title": "Hands-on Exercise 06 - Time-Oriented Data",
    "section": "5.2. Create Slopegraph",
    "text": "5.2. Create Slopegraph\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html",
    "title": "Hands-on Exercise 07 - Choropleth Mapping",
    "section": "",
    "text": "In the first part of the seventh lesson, we learn to create choropleth maps to visualise spaital distributions of data. This will be done using the tmap package."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#installing-and-loading-packages",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#installing-and-loading-packages",
    "title": "Hands-on Exercise 07 - Choropleth Mapping",
    "section": "2.1. Installing and Loading Packages",
    "text": "2.1. Installing and Loading Packages\nWe will use the following R packages in addition to tidyverse for this exercise:\n\ntmap: to create choropleth maps\nsf: to handle geospatial data\n\nThe packages to be used can be installed and loaded into the R environment using the p_load() function from the pacman package:\n\npacman::p_load(tidyverse, tmap, sf)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#the-data",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#the-data",
    "title": "Hands-on Exercise 07 - Choropleth Mapping",
    "section": "2.2. The Data",
    "text": "2.2. The Data\nWe will use the following data sets for this exercise:\n\n\n\nData\nFormat\nSource\nDescription\n\n\n\n\nMaster Plan 2014 Subzone Boundary (Web)\nESRI shapefile\ndata.gov.sg\nGeospatial data containing geographical boundary of Singapore at the planning subzone level.\n\n\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020\nCSV\nsingstat.gov.sg\nAspatial data containing demographics by Planning Area (PA) and Subzone (SZ).\n\n\n\n\n2.2.1. Import Geospatial Data\nWe will read the geospatial data into the R environment using the st_read() function from the sf package. We will import the MP14_SUBZONE_WEB_PL shapefile into into R as a simple feature data frame.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\noelnomel\\ISSS608-VAA\\hands_on_ex\\hands_on_ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nLooking at the data, it is observed that the simple feature data frame contains 323 features and 15 fields. The data frame contains multipolygons and it is projected using SVY21, Singapore’s coordinate system.\n\n\n2.3.2. Import Aspatial Data\nLastly, we will read the aspatial data into the R environment using the read_csv() function from the readr package found in tidyverse.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\nglimpse(popdata)\n\nRows: 984,656\nColumns: 7\n$ PA   &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ AG   &lt;chr&gt; \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to…\n$ Sex  &lt;chr&gt; \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"M…\n$ TOD  &lt;chr&gt; \"HDB 1- and 2-Room Flats\", \"HDB 3-Room Flats\", \"HDB 4-Room Flats\"…\n$ Pop  &lt;dbl&gt; 0, 10, 30, 50, 0, 0, 40, 0, 0, 10, 30, 60, 0, 0, 40, 0, 0, 10, 30…\n$ Time &lt;dbl&gt; 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,…\n\n\nUsing glimpse to view the data, it is observed that the data contains 984,656 records with 7 columns including the Planning Area, Subzone (SZ), and Age Group (AG)."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#data-preparation",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#data-preparation",
    "title": "Hands-on Exercise 07 - Choropleth Mapping",
    "section": "2.3. Data Preparation",
    "text": "2.3. Data Preparation\nWe will first prepare a data table with values from year 2020 containing the variables PA, SZ, YOUNG, ECONOMICALLY ACTIVE, AGED, TOTAL, DEPENDENCY based on the following definitions:\n\nYOUNG: AG 0_to_4 to AG 20_to_24\nECONOMICALLY ACTIVE: AG 25_to_29 to AG 60_to_64\nAGED: AG 65_to_69 to AG 90_and_over\nTOTAL: Sum of population of all age groups\nDEPENDENCY: Ratio of YOUNG and AGED to ECONOMICALLY ACTIVE\n\n\n2.3.1. Data Wrangling\nWe will create the desired data frame using the following code:\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;% \n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+ \n           rowSums(.[13:15])) %&gt;%\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;% \n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n         /`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n         `ECONOMY ACTIVE`, `AGED`, \n         `TOTAL`, `DEPENDENCY`) %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n            .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\n\n2.3.2. Joining Geospatial and Aspatial Data\nWe will use the left_join() function from the dplyr package to merge the aspatial data to the geospatial data. This ensures that the simple feature data frame is retained.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nTo save this merged data frame for future use, we can use write_rds() function from the readr package to create a RDS file locally.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\nThe RDS file can be imported into R using the read_rds() function from the readr package:\n\nmpsz_pop2020 &lt;- read_rds(\"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#quick-map-using-qtm",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#quick-map-using-qtm",
    "title": "Hands-on Exercise 07 - Choropleth Mapping",
    "section": "3.1. Quick Map Using qtm()",
    "text": "3.1. Quick Map Using qtm()\nWhen a quick visualisation is required, we can use qtm() to create a concise and default visualisation.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#using-tmap-elements",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#using-tmap-elements",
    "title": "Hands-on Exercise 07 - Choropleth Mapping",
    "section": "3.2. Using tmap Elements",
    "text": "3.2. Using tmap Elements\nUsing the elements of tmap, we are able to customise and adjust the aesthetics of individual layers.\n\nBase Maptm_fill() and tm_border()tm_polygons()\n\n\nThe basic building block of tmap is tm_shape() and tm_polygons(). tm_shape() is used to define the input data, and tm_polygons() is used to draw the polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\ntm_fill() is used to shade the polygons by using the default colour scheme while tm_border() adds borders of the shapefule onto the map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nThe subzones are shaded according to the dependency ratio. We can add borders using the following code:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") + \n  tm_borders(lwd = 0.1, alpha = 1)\n\n\n\n\n\n\ntm_polygons() is a wrapper of tm_fill() and tm_border() by fulfilling the both functions in one. We can use geographical distribution of a selected variable by using tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#data-classification-methods",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#data-classification-methods",
    "title": "Hands-on Exercise 07 - Choropleth Mapping",
    "section": "3.3. Data Classification Methods",
    "text": "3.3. Data Classification Methods\ntmap provides ten data classification methods to group a large number of observations into data ranges or classes: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\n\nsdequalprettyquantilekmeanshclustbclustfisherjenks\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nUsing different number of classes narrows the range of each bin and increases the range of colours used to represent each bin.\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#using-custom-break-points",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07.html#using-custom-break-points",
    "title": "Hands-on Exercise 07 - Choropleth Mapping",
    "section": "3.4. Using Custom Break Points",
    "text": "3.4. Using Custom Break Points\nIt is possible to override the default breaks computerd by the built-in styles (as seen above) by using the breaks argument in tm_fill().\n\n\n\n\n\n\nImportant\n\n\n\nIn order to have n categories, n+1 elements must be specified in the breaks argument as the breaks include a minimum and maximum.\nValues must also be specified in ascending order.\n\n\nFirst, we will view the descriptive statistics of the variable before deciding on the break points.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nUsing the results, we can choose to set the break points to be at 0.60, 0.70, 0.80, and 0.90, excluding the minimum of 0 and maximum of 1.00.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07_2.html",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07_2.html",
    "title": "Hands-on Exercise 7 - Geospatial Data Point",
    "section": "",
    "text": "In the first part of the seventh lesson, we learn to create choropleth maps to visualise spaital distributions of data. This will be done using the tmap package."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07_2.html#installing-and-loading-packages",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07_2.html#installing-and-loading-packages",
    "title": "Hands-on Exercise 7 - Geospatial Data Point",
    "section": "2.1. Installing and Loading Packages",
    "text": "2.1. Installing and Loading Packages\nWe will use the following R packages in addition to tidyverse for this exercise:\n\ntmap: to create choropleth maps\nsf: to handle geospatial data\n\nThe packages to be used can be installed and loaded into the R environment using the p_load() function from the pacman package:\n\npacman::p_load(tidyverse, tmap, sf)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07_2.html#the-data",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07_2.html#the-data",
    "title": "Hands-on Exercise 7 - Geospatial Data Point",
    "section": "2.2. The Data",
    "text": "2.2. The Data\nWe will use the following data sets for this exercise:\n\n\n\nData\nFormat\nSource\nDescription\n\n\n\n\nMaster Plan 2014 Subzone Boundary (Web)\nESRI shapefile\ndata.gov.sg\nGeospatial data containing geographical boundary of Singapore at the planning subzone level.\n\n\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020\nCSV\nsingstat.gov.sg\nAspatial data containing demographics by Planning Area (PA) and Subzone (SZ).\n\n\n\n\n2.2.1. Import Geospatial Data\nWe will read the geospatial data into the R environment using the st_read() function from the sf package. We will import the MP14_SUBZONE_WEB_PL shapefile into into R as a simple feature data frame.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\noelnomel\\ISSS608-VAA\\hands_on_ex\\hands_on_ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nLooking at the data, it is observed that the simple feature data frame contains 323 features and 15 fields. The data frame contains multipolygons and it is projected using SVY21, Singapore’s coordinate system.\n\n\n2.3.2. Import Aspatial Data\nLastly, we will read the aspatial data into the R environment using the read_csv() function from the readr package found in tidyverse.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\nglimpse(popdata)\n\nRows: 984,656\nColumns: 7\n$ PA   &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ AG   &lt;chr&gt; \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to…\n$ Sex  &lt;chr&gt; \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"M…\n$ TOD  &lt;chr&gt; \"HDB 1- and 2-Room Flats\", \"HDB 3-Room Flats\", \"HDB 4-Room Flats\"…\n$ Pop  &lt;dbl&gt; 0, 10, 30, 50, 0, 0, 40, 0, 0, 10, 30, 60, 0, 0, 40, 0, 0, 10, 30…\n$ Time &lt;dbl&gt; 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,…\n\n\nUsing glimpse to view the data, it is observed that the data contains 984,656 records with 7 columns including the Planning Area, Subzone (SZ), and Age Group (AG)."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex07/hands_on_ex07_2.html#data-preparation",
    "href": "hands_on_ex/hands_on_ex07/hands_on_ex07_2.html#data-preparation",
    "title": "Hands-on Exercise 7 - Geospatial Data Point",
    "section": "2.3. Data Preparation",
    "text": "2.3. Data Preparation\nWe will first prepare a data table with values from year 2020 containing the variables PA, SZ, YOUNG, ECONOMICALLY ACTIVE, AGED, TOTAL, DEPENDENCY based on the following definitions:\n\nYOUNG: AG 0_to_4 to AG 20_to_24\nECONOMICALLY ACTIVE: AG 25_to_29 to AG 60_to_64\nAGED: AG 65_to_69 to AG 90_and_over\nTOTAL: Sum of population of all age groups\nDEPENDENCY: Ratio of YOUNG and AGED to ECONOMICALLY ACTIVE\n\n\n2.3.1. Data Wrangling\nWe will create the desired data frame using the following code:\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;% \n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+ \n           rowSums(.[13:15])) %&gt;%\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;% \n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n         /`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n         `ECONOMY ACTIVE`, `AGED`, \n         `TOTAL`, `DEPENDENCY`) %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n            .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\n\n2.3.2. Joining Geospatial and Aspatial Data\nWe will use the left_join() function from the dplyr package to merge the aspatial data to the geospatial data. This ensures that the simple feature data frame is retained.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nTo save this merged data frame for future use, we can use write_rds() function from the readr package to create a RDS file locally.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\nThe RDS file can be imported into R using the read_rds() function from the readr package:\n\nmpsz_pop2020 &lt;- read_rds(\"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Noel’s Learning Journey in Visual Analytics",
    "section": "",
    "text": "Welcome to Noel’s ISSS608 website!\nThis website documents my learning journey in Visual Analytics :)"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html",
    "title": "In-class Exercise 01",
    "section": "",
    "text": "First, we will download the School questionnaire data file from the PISA 2022 Database. As there is only the SAS and SPSS versions available, we will download the SAS version.\n\n\nNext, We will import the dataset into the R environment. In order to import a SAS file into R, we have to first load the haven package. We will do so by calling the p_load() function from the pacman package.\nIn addition to haven, we will load tidyverse where the ggplot2 package can be found. We will use haven to load the SAS file and ggplot2 to plot the statistical graphs.\n\npacman::p_load(haven, tidyverse)\n\n\n\n\nWe will now use the read_sas function from the haven package to load the dataset into R as stu_quest:\n\nstu_qqq &lt;- read_sas(data_file = \"data/cy08msp_stu_qqq.sas7bdat\")\n\n\n\n\nAs this dataset consists of global responses, we will filter out only the responses from Singapore:\n\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")\n\nWe will store the filtered dataset in the rds format for future use on R:\n\nwrite_rds(stu_qqq_SG, \"data/stu_qqq_SG.rds\")\n\nThe rds file can be loaded into the R environment by using the read_rds() function from the readr package found in tidyverse:\n\nstu_qqq_SG &lt;- read_rds(\"data/stu_qqq_SG.rds\")"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html#loading-relevant-packages",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html#loading-relevant-packages",
    "title": "In-class Exercise 01",
    "section": "",
    "text": "Next, We will import the dataset into the R environment. In order to import a SAS file into R, we have to first load the haven package. We will do so by calling the p_load() function from the pacman package.\nIn addition to haven, we will load tidyverse where the ggplot2 package can be found. We will use haven to load the SAS file and ggplot2 to plot the statistical graphs.\n\npacman::p_load(haven, tidyverse)"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html#import-data",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html#import-data",
    "title": "In-class Exercise 01",
    "section": "",
    "text": "We will now use the read_sas function from the haven package to load the dataset into R as stu_quest:\n\nstu_qqq &lt;- read_sas(data_file = \"data/cy08msp_stu_qqq.sas7bdat\")"
  },
  {
    "objectID": "in_class_ex/in_class_ex01/in_class_ex01.html#prepare-data",
    "href": "in_class_ex/in_class_ex01/in_class_ex01.html#prepare-data",
    "title": "In-class Exercise 01",
    "section": "",
    "text": "As this dataset consists of global responses, we will filter out only the responses from Singapore:\n\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")\n\nWe will store the filtered dataset in the rds format for future use on R:\n\nwrite_rds(stu_qqq_SG, \"data/stu_qqq_SG.rds\")\n\nThe rds file can be loaded into the R environment by using the read_rds() function from the readr package found in tidyverse:\n\nstu_qqq_SG &lt;- read_rds(\"data/stu_qqq_SG.rds\")"
  },
  {
    "objectID": "in_class_ex/in_class_ex03/in_class_ex03.html",
    "href": "in_class_ex/in_class_ex03/in_class_ex03.html",
    "title": "In-class Exercise 03",
    "section": "",
    "text": "We were tasked to critique Figure 5 presented in the State of the Industry report prepared by the Data Visualization Society. The figure is on page 14 of the report found in this link.\n\norganisation of the legends is confusing\ntext on pie chart contradicts the legend (e.g. “Employee” is labelled on dark purple segment on pie chart instead of light purple segment)\nEmployee + Other Roles and Employee And Freelance – are they mutually exclusive?\nbar chart underneath pie chart is not clear – how to read??"
  },
  {
    "objectID": "in_class_ex/in_class_ex03/in_class_ex03.html#create-additional-individual-plots",
    "href": "in_class_ex/in_class_ex03/in_class_ex03.html#create-additional-individual-plots",
    "title": "In-class Exercise 03",
    "section": "Create Additional Individual Plots",
    "text": "Create Additional Individual Plots\nWe will continue from last week’s in-class exercise completed on Tableau.\nFirst, we create a scatterplot of sales vs profit by state.\nBy default, Tableau aggregates data by default to reduce the number of data points to be rendered. We can toggle this setting under Analysis.\n\n\nWe can toggle the Level of Detail to be displayed on Tableau. For example, we can drag State into the Detail box to display the scatterplot by State\n\nThe data points are clustered together. We can use some in-built calculation function on Tableau to transform the raw data points into derived values such as percentile.\nThe calculation functions can be accessed by clicking on the dropdown arrow next to the variable, and selecting Quick Table Calculation"
  },
  {
    "objectID": "in_class_ex/in_class_ex03/in_class_ex03.html#scatterplot-with-marginal-boxplot",
    "href": "in_class_ex/in_class_ex03/in_class_ex03.html#scatterplot-with-marginal-boxplot",
    "title": "In-class Exercise 03",
    "section": "scatterplot with marginal boxplot",
    "text": "scatterplot with marginal boxplot\nmake individual plot\nmake dashboard\nmake coordinated linked view - all plots must have a common link (ID in this case)"
  },
  {
    "objectID": "in_class_ex/in_class_ex03/in_class_ex03.html#create-dashboard",
    "href": "in_class_ex/in_class_ex03/in_class_ex03.html#create-dashboard",
    "title": "In-class Exercise 03",
    "section": "Create Dashboard",
    "text": "Create Dashboard\nA dashboard displays a smaller view of each selected sheet on one single page when published to Tableau Public."
  },
  {
    "objectID": "in_class_ex/in_class_ex03/in_class_ex03.html#create-story",
    "href": "in_class_ex/in_class_ex03/in_class_ex03.html#create-story",
    "title": "In-class Exercise 03",
    "section": "Create Story",
    "text": "Create Story\nA Story allows us to present each Tableau sheet on a single page when published to Tableau Public."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html",
    "title": "Is Every School Truly A Good School In Singapore?",
    "section": "",
    "text": "Singapore often tops the charts in global rankings, and this is definitely the case for the nation’s education system. Education is often seen as the gateway to success, and Singaporean parents, understandably, seek the best education opportunities for their children.\nIn this exercise, we delve deeper into the PISA 2022 database in the hopes of gaining insights on the following:\n\nHow are Singaporean students performing in mathematics, reading, and science?\nAre there any relationships between the students’ demographic profile and their performance in these subjects?\nIs there any relationship between the learning environment that the students are in and their results?\nIs every school in Singapore a good school that can bring out the best in every child?\n\nWe will use Exploratory Data Analysis (EDA) to address the above questions."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#loading-relevant-packages",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#loading-relevant-packages",
    "title": "Is Every School Truly A Good School In Singapore?",
    "section": "2.1. Loading Relevant Packages",
    "text": "2.1. Loading Relevant Packages\nBefore we can import the dataset into the R environment, we have to load the relevant packages to facilitate the import process. In order to import a SAS file into R, we have to first load the haven package. We will do so by calling the p_load() function from the pacman package.\nIn addition to haven, we will load tidyverse where the ggplot2 package can be found, and patchwork. We will use haven to load the SAS file, ggplot2 to plot the statistical graphs, and patchwork to create composite graphs.\n\npacman::p_load(haven, tidyverse, patchwork)"
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#import-data",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#import-data",
    "title": "Is Every School Truly A Good School In Singapore?",
    "section": "2.2. Import Data",
    "text": "2.2. Import Data\nWe will now use the read_sas() function from the haven package to load the dataset into R as stu_qqq:\n\nstu_qqq &lt;- read_sas(data_file = \"data/cy08msp_stu_qqq.sas7bdat\")\n\nNext, we will take a look at the dataset using the following steps:\nFirst, we navigate to the “Environment” panel on the top right hand corner of RStudio. We can observe that the dataset contains 613,744 responses and 1,279 columns.\n\nNext, click on the blank space next to stu_qqq to open a view of the dataset in a new tab.\n\nWe can see that students from different countries responded to the questionnaire and the country codes are recorded under the column “CNT”."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#distribution-of-singapore-students-performance",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#distribution-of-singapore-students-performance",
    "title": "Is Every School Truly A Good School In Singapore?",
    "section": "4.1. Distribution of Singapore Students’ Performance",
    "text": "4.1. Distribution of Singapore Students’ Performance\nFirstly, we will visualise the distribution of Singapore students’ performance in each of the subjects. As the values to be plotted are continuous variables, we will visualise them using histograms. Using patchwork, we can add a corresponding boxplot to each histogram to provide us with further insights.\nFirst, we create each individual histogram and boxplot and store them as separate variables. This makes it easier for us to combine different plots using patchwork later on.\n\n\nCodes to generate individual plots\nmath_hist &lt;- ggplot(data = stu_sg_data,\n       aes(x = MATH_PV_AVG)) +\n  geom_histogram(color = \"grey40\",\n                 fill = \"lightblue\") +\n  geom_vline(xintercept = median(stu_sg_data$MATH_PV_AVG),\n             color = \"grey50\",\n             lwd = 1) +\n  coord_cartesian(ylim = c(0, 600),\n                  xlim = c(150, 850)) +\n  ylab(\"Frequency\") +\n  xlab(\"\") +\n  theme_classic() +\n  ggtitle(\"Distribution of Maths Avg PVs\") +\n  theme(plot.title = element_text(size = 8)) \n\nmath_box &lt;- ggplot(data = stu_sg_data,\n       aes(x = MATH_PV_AVG,\n           y = \"\")) +\n  theme_classic() +\n  geom_boxplot(color = \"grey40\",\n                 fill = \"lightblue\") +\n  coord_cartesian(xlim = c(150, 850)) +\n  ylab(\"\") +\n  xlab(\"Plausible Values\") +\n  theme(axis.ticks.y = element_blank(),\n        axis.line.y = element_blank()) +\n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"red2\",\n               size = 2)\n\nread_hist &lt;- ggplot(data = stu_sg_data,\n       aes(x = READ_PV_AVG)) +\n  geom_histogram(color = \"grey40\",\n                 fill = \"rosybrown2\") +\n  geom_vline(xintercept = median(stu_sg_data$READ_PV_AVG),\n             color = \"grey50\",\n             lwd = 1) +\n  coord_cartesian(ylim = c(0, 600),\n                  xlim = c(150, 850)) +\n  ylab(\"\") +\n  xlab(\"\") +\n  theme_classic() +\n  ggtitle(\"Distribution of Reading Avg PVs\") +\n  theme(plot.title = element_text(size = 8))\n\nread_box &lt;- ggplot(data = stu_sg_data,\n       aes(x = READ_PV_AVG,\n           y = \"\")) +\n  theme_classic() +\n  geom_boxplot(color = \"grey40\",\n                 fill = \"rosybrown2\") +\n  coord_cartesian(xlim = c(150, 850)) +\n  ylab(\"\") +\n  xlab(\"Plausible Values\") +\n  theme(axis.ticks.y = element_blank(),\n        axis.line.y = element_blank()) +\n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"red2\",\n               size = 2)\n\nsci_hist &lt;- ggplot(data = stu_sg_data,\n       aes(x = SCI_PV_AVG)) +\n  geom_histogram(color = \"grey40\",\n                 fill = \"palegreen3\") +\n  geom_vline(xintercept = median(stu_sg_data$SCI_PV_AVG),\n             color = \"grey50\",\n             lwd = 1) +\n  coord_cartesian(ylim = c(0, 600),\n                  xlim = c(150, 850)) +\n  ylab(\"\") +\n  xlab(\"\") +\n  theme_classic() +\n  ggtitle(\"Distribution of Science Avg PVs\") +\n  theme(plot.title = element_text(size = 8))\n\nsci_box &lt;- ggplot(data = stu_sg_data,\n       aes(x = SCI_PV_AVG,\n           y = \"\")) +\n  theme_classic() +\n  geom_boxplot(color = \"grey40\",\n                 fill = \"palegreen3\") +\n  coord_cartesian(xlim = c(150, 850)) +\n  ylab(\"\") +\n  xlab(\"Plausible Values\") +\n  theme(axis.ticks.y = element_blank(),\n        axis.line.y = element_blank()) +\n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"red2\",\n               size = 2)\n\n\n\n((math_hist / math_box) +\n  plot_layout(nrow = 2, heights = c(3, 1))) | \n  ((read_hist / read_box) +\n  plot_layout(nrow = 2, heights = c(3, 1))) | \n  ((sci_hist / sci_box) +\n  plot_layout(nrow = 2, heights = c(3, 1)))\n\n\n\n\nWe can observe from the graphs above that the distribution for the average Plausible Values for Maths, Reading, and Science generally resemble a normal distribution curve. It is observed from the boxplot that the average values for each subject (represented by the red dot) is slightly lower than than the respective median values (represented by the grey line). The median value is also observed to occur slightly lower than the mode. This suggests a slight left skew in the data. This can be observed in the histogram where a slightly longer tail is seen on the left side of the distribution, where some observations of extreme lower values are seen. This observation of left skewed distribution is most obvious in the distribution of Reading.\nThis shows that half of the Singapore student sample size received Plausible Value scores for each subject that are on the higher end of the maximum possible Plausible Values.\n\n\n\n\n\n\nTip\n\n\n\nWe use different colours to represent one subject in this graph, and in the subsequent graphs. Some common colours that can be used in a ggplot2 graph can be found on this link."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#distribution-by-gender",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#distribution-by-gender",
    "title": "Is Every School Truly A Good School In Singapore?",
    "section": "4.2. Distribution by Gender",
    "text": "4.2. Distribution by Gender\nNext, we will explore the role of gender in the students’ performance in each of the subjects. We will use the same method as above, where each plot is generated and saved as a variable for easier combination using patchwork later on.\nIn this part, we use facet_grid() to display the data by gender.\n\n\nCodes to generate individual plots\nmath_box_gender &lt;- ggplot(data = stu_sg_data,\n       aes(x = MATH_PV_AVG,\n           y = \"\")) +\n  facet_grid(~GENDER) +\n  theme_classic() +\n  geom_boxplot(notch = TRUE,\n               color = \"grey40\",\n                 fill = \"lightblue\") +\n  ylab(\"\") +\n  xlab(\"\") +\n  theme(axis.ticks.x = element_blank(),\n        axis.line.x = element_blank()) +\n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"red2\",\n               size = 2) +\n  coord_cartesian(ylim = c(150, 850)) +\n  coord_flip() +\n  ggtitle(\"Maths PV\")\n\nread_box_gender &lt;- ggplot(data = stu_sg_data,\n       aes(x = READ_PV_AVG,\n           y = \"\")) +\n  facet_grid(~GENDER) +\n  theme_classic() +\n  geom_boxplot(notch = TRUE,\n               color = \"grey40\",\n               fill = \"rosybrown2\") +\n  ylab(\"\") +\n  xlab(\"\") +\n  theme(axis.ticks.x = element_blank(),\n        axis.line.x = element_blank()) +\n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"red2\",\n               size = 2) +\n  coord_cartesian(ylim = c(150, 850)) +\n  coord_flip() +\n  ggtitle(\"Reading PV\")\n\nsci_box_gender &lt;- ggplot(data = stu_sg_data,\n       aes(x = SCI_PV_AVG,\n           y = \"\")) +\n  facet_grid(~GENDER) +\n  theme_classic() +\n  geom_boxplot(notch = TRUE,\n               color = \"grey40\",\n               fill = \"palegreen3\") +\n  ylab(\"\") +\n  xlab(\"\") +\n  theme(axis.ticks.x = element_blank(),\n        axis.line.x = element_blank()) +\n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"red2\",\n               size = 2) +\n  coord_cartesian(ylim = c(150, 850)) +\n  coord_flip() +\n  ggtitle(\"Science PV\")\n\n\n\n(math_box_gender |\n  read_box_gender | \n   sci_box_gender) \n\n\n\n\nFrom the boxplots, it is observed that the median Plausible Values for Maths is higher among male students. The highest Plausible Value for Maths among the male students is higher than the highest Plausible Value for Maths among female students. On the other hand, the lowest Plausible Value for Maths among the male students is lower than the lowest Plausible Value for Maths among female students.\nNext, it is observed that the median Plausible Values for Reading is higher among female students. However, the highest Plausible Value for Reading among the male students is higher than the highest Plausible Value for Reading among female students. The lowest Plausible Value for Reading among the male students is lower than the lowest Plausible Value for Reading among female students.\nIt is observed that the median Plausible Values for Science is slightly higher among male students. The highest Plausible Value for Science among the male students is higher than the highest Plausible Value for Science among female students. On the other hand, the lowest Plausible Value for Science among the male students is lower than the lowest Plausible Value for Science among female students.\nOverall, it can be observed that the variance of Plausible Values among male students across all three subjects is higher than that of female students."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#relationship-between-socioeconomic-status-and-performance",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#relationship-between-socioeconomic-status-and-performance",
    "title": "Is Every School Truly A Good School In Singapore?",
    "section": "4.3. Relationship Between Socioeconomic Status and Performance",
    "text": "4.3. Relationship Between Socioeconomic Status and Performance\nAccording to the PISA report, the Economic, Social, and Culture status is an index derived from three indicators related to family background. The index is standardised, such that 0 is the score of an average OECD student and 1 is the standard deviation across approximately equally weighted OECD countries.\n\n\nCodes to generate individual plots\nescs_math &lt;- ggplot(data = stu_sg_data, \n       aes(x = MATH_PV_AVG,\n           y = ESCS)) +\n  geom_point(color = \"lightblue\",\n             alpha = 0.5) +\n  geom_smooth(size = 0.5,\n              color = \"red2\") +\n  coord_cartesian(xlim = c(150, 850)) +\n  theme_classic() +\n  xlab(\"Plausible Values\") +\n  ggtitle(\"ESCS vs Maths\")\n\n\nescs_read &lt;- ggplot(data = stu_sg_data, \n       aes(x = READ_PV_AVG,\n           y = ESCS)) +\n  geom_point(color = \"rosybrown2\", \n             alpha = 0.5) +\n  geom_smooth(size = 0.5,\n              color = \"red2\") +\n  coord_cartesian(xlim = c(150, 850)) +\n  ylab(\"\") +\n  theme(axis.ticks.y = element_blank()) +\n  theme_classic() +\n  xlab(\"Plausible Values\") +\n  ggtitle(\"ESCS vs Reading\")\n\nescs_sci &lt;- ggplot(data = stu_sg_data, \n       aes(x = SCI_PV_AVG, \n           y = ESCS)) +\n  geom_point(color = \"palegreen3\",\n             alpha = 0.5) +\n  geom_smooth(size = 0.5,\n              color = \"red2\") +\n  coord_cartesian(xlim = c(150, 850)) +\n  ylab(\"\") +\n  theme(axis.ticks.y = element_blank()) +\n  theme_classic() +\n  xlab(\"Plausible Values\") +\n  ggtitle(\"ESCS vs Science\")\n\n\n\nescs_math | escs_read | escs_sci\n\n\n\n\nFrom the scatterplots above, we can observe that generally, as the ESCS index increases, higher Plausible Values are obtained for each subject. However, we may not be able to conclude that there is a very strong linear relationship between ESCS and the Plausible Values as the points do not appear to follow closely to a upward-trending line.\nThe observations of the trends between ESCS and Maths, and ESCS and Science are generally similar - the rate of increase in Plausible Values appear to be faster when ESCS is below 0, while it appears to decrease slightly when ESCS is above 0. On the other hand, is is observed that there was a slight decrease in the trend between ESCS and Reading when Plausible Valus is less than 400, indicating that there were students who received higher Plausible Values for Reading compared to peers of a slightly higher ESCS."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#relationship-between-student-teacher-relationship-and-performance",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#relationship-between-student-teacher-relationship-and-performance",
    "title": "Is Every School Truly A Good School In Singapore?",
    "section": "4.4. Relationship Between Student-Teacher Relationship and Performance",
    "text": "4.4. Relationship Between Student-Teacher Relationship and Performance\nAs the dataset did not provide more granular details on the type of school, whether public, autonomous, or independent, that the students were enrolled in, we have to find proxies to estimate the learning environment provided to each student. One such proxy we use in this exercise is the quality of student-teacher relationship as perceived by the students1.\n\n\nCodes to generate individual plots\nrelatst_math &lt;- ggplot(data = stu_sg_data, \n       aes(x = MATH_PV_AVG, \n           y = RELATST)) +\n  geom_point(color = \"lightblue\",\n             alpha = 0.5) +\n  geom_smooth(size = 0.5,\n              color = \"red2\") +\n  coord_cartesian(xlim = c(150, 850)) +\n  theme_classic() +\n  xlab(\"Plausible Values\") +\n  ylab(\"Student-Teacher Relationship\") +\n  ggtitle(\"Student-Teacher Relation vs Maths\") +\n  theme(plot.title = element_text(size = 8))\n\nrelatst_read &lt;- ggplot(data = stu_sg_data, \n       aes(x = READ_PV_AVG,\n           y = RELATST)) +\n  geom_point(color = \"rosybrown2\", \n             alpha = 0.5) +\n  geom_smooth(size = 0.5,\n              color = \"red2\") +\n  coord_cartesian(xlim = c(150, 850)) +\n  theme_classic() +\n  xlab(\"Plausible Values\") +\n  ylab(\"\") +\n  ggtitle(\"Student-Teacher Relation vs Read\") +\n  theme(plot.title = element_text(size = 8))\n\nrelatst_sci &lt;- ggplot(data = stu_sg_data, \n       aes(x = SCI_PV_AVG,\n           y = RELATST)) +\n  geom_point(color = \"palegreen3\",\n             alpha = 0.5) +\n  geom_smooth(size = 0.5,\n              color = \"red2\") +\n  coord_cartesian(xlim = c(150, 850)) +\n  theme_classic() +\n  xlab(\"Plausible Values\") +\n  ylab(\"\") +\n  ggtitle(\"Student-Teacher Relation vs Science\") +\n  theme(plot.title = element_text(size = 8))\n\n\n\nrelatst_math | relatst_read | relatst_sci\n\n\n\n\nWe see that the relationship between the quality of student-teacher relationships and the Plausible Values for each subject is not very obvious. This could be due to the presence of outliers in the dataset. We will redo the visualisation without the outliers.\n\n\nCodes to generate individual plots\nrelatst_math &lt;- ggplot(data = subset(stu_sg_data, RELATST &gt; -5), \n       aes(x = MATH_PV_AVG, \n           y = RELATST)) +\n  geom_point(color = \"lightblue\",\n             alpha = 0.5) +\n  geom_smooth(size = 0.5,\n              color = \"red2\") +\n  coord_cartesian(xlim = c(150, 850)) +\n  theme_classic() +\n  xlab(\"Plausible Values\") +\n  ylab(\"Student-Teacher Relationship\") +\n  ggtitle(\"Student-Teacher Relation vs Maths\") +\n  theme(plot.title = element_text(size = 8))\n\nrelatst_read &lt;- ggplot(data = subset(stu_sg_data, RELATST &gt; -5), \n       aes(x = READ_PV_AVG,\n           y = RELATST)) +\n  geom_point(color = \"rosybrown2\", \n             alpha = 0.5) +\n  geom_smooth(size = 0.5,\n              color = \"red2\") +\n  coord_cartesian(xlim = c(150, 850)) +\n  theme_classic() +\n  xlab(\"Plausible Values\") +\n  ylab(\"\") +\n  ggtitle(\"Student-Teacher Relation vs Read\") +\n  theme(plot.title = element_text(size = 8))\n\nrelatst_sci &lt;- ggplot(data = subset(stu_sg_data, RELATST &gt; -5), \n       aes(x = SCI_PV_AVG,\n           y = RELATST)) +\n  geom_point(color = \"palegreen3\",\n             alpha = 0.5) +\n  geom_smooth(size = 0.5,\n              color = \"red2\") +\n  coord_cartesian(xlim = c(150, 850)) +\n  theme_classic() +\n  xlab(\"Plausible Values\") +\n  ylab(\"\") +\n  ggtitle(\"Student-Teacher Relation vs Science\") +\n  theme(plot.title = element_text(size = 8))\n\n\n\nrelatst_math | relatst_read | relatst_sci\n\n\n\n\nFrom the scatterplots above, we can observe that generally, as the perceived quality of student-teacher relationship increases, higher Plausible Values are obtained for each subject. However, we may not be able to conclude that there is a very strong linear relationship between quality of student-teacher relationship and the Plausible Values as the points do not appear to follow closely to a upward-trending line.\nThe observations of the trends between quality of student-teacher relationship and Maths, and quality of student-teacher relationship and Science are generally similar - the rate of increase in Plausible Values appear to be faster when quality of student-teacher relationship is below 0, while it appears to decrease slightly when quality of student-teacher relationship is above 0.\nOn the other hand, the positive relationship between quality of student-teacher relationship and Reading appears to be the weakest. It is observed that the gradient on the best fit curve is small, indicating that there is a small change to Plausible Value as the quality of student-teacher relationship increases."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#relationship-between-sense-of-belonging-to-school-and-performance",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#relationship-between-sense-of-belonging-to-school-and-performance",
    "title": "Is Every School Truly A Good School In Singapore?",
    "section": "4.5. Relationship Between Sense of Belonging to School and Performance",
    "text": "4.5. Relationship Between Sense of Belonging to School and Performance\nFinally, we explore the relationship between the students’ sense of belonging to their schools and their academic performance2. Sense of belonging is also used as a proxy to determine if the students were provided conducive learning environments that could help them excel. The use of this proxy, however, is based on the assumption that a student would feel a greater sense of belonging to the school if the environment was favourable to them building strong social connections, based on how the index was constructed by OECD.\n\n\nCodes to generate individual plots\nbelong_math &lt;- ggplot(data = stu_sg_data, \n       aes(x = MATH_PV_AVG,\n           y = BELONG)) +\n  geom_point(color = \"lightblue\",\n             alpha = 0.5) +\n  geom_smooth(size = 0.5,\n              color = \"red2\") +\n  coord_cartesian(xlim = c(150, 850)) +\n  theme_classic() +\n  xlab(\"Plausible Values\") +\n  ylab(\"Sense of Belonging to School\") +\n  ggtitle(\"Belonging to School vs Maths\") +\n  theme(plot.title = element_text(size = 8))\n\nbelong_read &lt;- ggplot(data = stu_sg_data, \n       aes(x = READ_PV_AVG,\n           y = BELONG)) +\n  geom_point(color = \"rosybrown2\",\n             alpha = 0.5) +\n  geom_smooth(size = 0.5,\n              color = \"red2\") +\n  coord_cartesian(xlim = c(150, 850)) +\n  theme_classic() +\n  xlab(\"Plausible Values\") +\n  ylab(\"\") +\n  ggtitle(\"Belonging to School vs Maths\") +\n  theme(plot.title = element_text(size = 8))\n\nbelong_sci &lt;- ggplot(data = stu_sg_data, \n       aes(x = SCI_PV_AVG,\n           y = BELONG)) +\n  geom_point(color = \"palegreen3\",\n             alpha = 0.5) +\n  geom_smooth(size = 0.5,\n              color = \"red2\") +\n  coord_cartesian(xlim = c(150, 850)) +\n  theme_classic() +\n  xlab(\"Plausible Values\") +\n  ylab(\"\") +\n  ggtitle(\"Belonging to School vs Maths\") +\n  theme(plot.title = element_text(size = 8))\n\n\n\nbelong_math | belong_read | belong_sci\n\n\n\n\nFrom the scatterplots above, it is observed that there is a slight relationship between the students’ sense of belonging to their school and the Plausible Values obtained for each subject. The observations for all three subjects are somewhat similar; most of the observations are clustered between the sense of belonging index of -2 to 2. Within this range, there is a spread of students who received low to high Plausible Values. There are also students whose sense of belonging index is lower than -2 or higher than 2. Similarly, there is also a spread of students who received low to high Plausible Values for each subject."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#distribution-of-gender",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#distribution-of-gender",
    "title": "Is Every School Truly A Good School In Singapore?",
    "section": "5.1. Distribution of Gender",
    "text": "5.1. Distribution of Gender\n\n\nShow the code\nggplot(data = stu_sg_data,\n       aes(x = GENDER)) +\n  geom_bar(color = \"grey40\",\n           fill = \"lavender\") +\n  theme_classic()\n\n\n\n\n\nIt appears that there is almost equal representation of male and female students in this study."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#distribution-of-escs",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#distribution-of-escs",
    "title": "Is Every School Truly A Good School In Singapore?",
    "section": "5.2. Distribution of ESCS",
    "text": "5.2. Distribution of ESCS\n\n\nShow the code\nescs_hist &lt;- ggplot(data = stu_sg_data,\n       aes(x = ESCS)) +\n  geom_histogram(color = \"grey40\",\n                 fill = \"lavender\") +\n  ggtitle(\"Distribution of ESCS\") +\n  xlab(\"\") +\n  ylab(\"Frequency\") +\n  coord_cartesian(xlim = c(-4, 4)) +\n  theme_classic()\n\nescs_box &lt;- ggplot(data = stu_sg_data,\n       aes(x = ESCS,\n           y = \"\")) +\n  geom_boxplot(fill = \"lavender\") +\n  geom_point(stat = \"summary\",\n             fun.y  = \"mean\",\n             color = \"salmon\",\n             size = 2) +\n  ylab(\"\") +\n  theme(axis.ticks.y = element_blank()) +\n  coord_cartesian(xlim = c(-4, 4)) +\n  theme_classic()\n\n\nescs_hist / escs_box +\n  plot_layout(nrow = 2, heights = c(2, 1)) \n\n\n\n\n\nIt is observed that most students who participated in this study have higher ESCS compared to the OECD average."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#distribution-of-student-teacher-relationship",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#distribution-of-student-teacher-relationship",
    "title": "Is Every School Truly A Good School In Singapore?",
    "section": "5.3. Distribution of Student-Teacher Relationship",
    "text": "5.3. Distribution of Student-Teacher Relationship\n\n\nShow the code\nrelatst_hist &lt;- ggplot(data = stu_sg_data,\n       aes(x = RELATST)) +\n  geom_histogram(color = \"grey40\",\n                 fill = \"lavender\") +\n  xlab(\"\") +\n  ylab(\"Frequency\") +\n  coord_cartesian(xlim = c(-11, 4)) +\n  theme_classic()\n\nrelatst_box &lt;- ggplot(data = stu_sg_data,\n       aes(x = RELATST, y = \"\")) +\n  geom_boxplot(fill = \"lavender\") +\n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"salmon\",\n               size = 2) +\n  ylab(\"\") +\n  theme(axis.ticks.y=element_blank()) +\n  coord_cartesian(xlim = c(-11, 4)) +\n  theme_classic()\n\nrelatst_hist / relatst_box +\n  plot_layout(nrow = 2, heights = c(2, 1))\n\n\n\n\n\nIt is observed that the median of the distribution occurs near 0, and that there is an extreme outlier in this measure."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#distribution-of-sense-of-belonging",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#distribution-of-sense-of-belonging",
    "title": "Is Every School Truly A Good School In Singapore?",
    "section": "5.4. Distribution of Sense of Belonging",
    "text": "5.4. Distribution of Sense of Belonging\n\n\nShow the code\nbelong_hist &lt;- ggplot(data = stu_sg_data,\n       aes(x = BELONG)) +\n  geom_histogram(color = \"grey40\",\n                 fill = \"lavender\") +\n  coord_cartesian(xlim = c(-4, 4)) +\n  theme_classic()\n\nbelong_box &lt;- ggplot(data = stu_sg_data,\n       aes(x = BELONG, y = \"\")) +\n  geom_boxplot(fill = \"lavender\") +\n  theme_classic() +\n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"salmon\",\n               size = 2) +\n  ylab(\"\") +\n  theme(axis.ticks.y = element_blank()) +\n  coord_cartesian(xlim = c(-4, 4)) +\n  theme_classic()\n\nbelong_hist / belong_box +\n  plot_layout(nrow = 2, heights = c(2, 1))\n\n\n\n\n\nIt is observed that the median of the distribution occurs below 0."
  },
  {
    "objectID": "take_home_ex/take_home_ex01/take_home_ex01.html#footnotes",
    "href": "take_home_ex/take_home_ex01/take_home_ex01.html#footnotes",
    "title": "Is Every School Truly A Good School In Singapore?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://www.apa.org/education-career/k12/relationships#:~:text=Solely%20improving%20students’%20relationships%20with,more%20conflict%20in%20their%20relationships.↩︎\nhttps://www.oecd-ilibrary.org/students-sense-of-belonging-at-school-and-their-relations-with-teachers_5jfxbg2lds9w.pdf↩︎"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html",
    "title": "Take-home Exercise 02 - DataVis Makeover",
    "section": "",
    "text": "In this exercise, we apply the data visualisation design principles and best practices learnt from this course to improve on the visualisations prepared by a classmate. This is a follow-up exercise on Take-home Exercise 1.\n\n\n\n\n\n\nPreviously on ISSS608…\n\n\n\nLast week, students attending ISSS608 used Exploratory Data Analysis (EDA) to gain insights on Singapore students’ performance in the 2022 Performance for International Student Assessment (2022). Relationships between factors such as socioeconomic status, gender, and school, and the students’ performance were explored."
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#loading-relevant-packages",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#loading-relevant-packages",
    "title": "Take-home Exercise 02 - DataVis Makeover",
    "section": "2.1. Loading Relevant Packages",
    "text": "2.1. Loading Relevant Packages\nBefore starting work on this exercise, we first have to review each classmate’s submission to identify areas for improvement. We will import the packages relevant to this makeover exercise using p_load() from the pacman package.\n\npacman::p_load(tidyverse, ggplot, \n               patchwork, ggthemes)"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#import-data",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#import-data",
    "title": "Take-home Exercise 02 - DataVis Makeover",
    "section": "2.2. Import Data",
    "text": "2.2. Import Data\nNext, we will import the data set into the R environment. We will be using the same data set that was prepared in Take-home Exercise 1. In that exercise, we saved the filtered data in the RDS format. Hence, we will import the same file using the read_rds() function from the readr package found in tidyverse:\n\nstu_qqq_SG &lt;- read_rds(\"data/stu_qqq_SG.rds\")"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#data-wrangling",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#data-wrangling",
    "title": "Take-home Exercise 02 - DataVis Makeover",
    "section": "3.1. Data Wrangling",
    "text": "3.1. Data Wrangling\nAs the dataset contains too many columns, we will extract only the relevant columns required for this exercise and keep the data as stu_sg_data. The columns we need are:\n\n\n\n\n\n\n\n\nCol Name\nLabel\nReason\n\n\n\n\nSTRATUM\nSchool Type\nTo explore relationships between the student’s chosen school and their academic performance\n\n\nST004D01T\nGender, where 1 is Female and 2 is Male\nTo explore if there are any relationships between gender and performance in the test\n\n\nESCS\nIndex of economic, social, and cultural status\nTo explore if there are any relationships between socioeconomic status and performance in the test\n\n\nPV1MATH to PV10MATH\nPlausible Values for Math\nTo derive average plausible value per student per subject for visualisation\n\n\nPV1READ to PV10READ\nPlausible Values for Reading\nTo derive average plausible value per student per subject for visualisation\n\n\nPV1SCIE to PV10SCIE\nPlausible Values for Science\nTo derive average plausible value per student per subject for visualisation\n\n\n\nNow that we have identified the columns needed for this analysis, we will use the following dplyr functions to extract the required columns. We will do some data wrangling to obtain the fields for analysis and to make the data more readable:\n\n# create a separate table of all plausible values for MATHS\nmath_cols &lt;- stu_qqq_SG %&gt;%\n  select(PV1MATH,PV2MATH,PV3MATH,PV4MATH,PV5MATH,\n         PV6MATH,PV7MATH,PV8MATH,PV9MATH,PV10MATH)\n\n# create a separate table of all plausible values for READ\nread_cols &lt;- stu_qqq_SG %&gt;%\n  select(PV1READ,PV2READ,PV3READ,PV4READ,PV5READ,\n         PV6READ,PV7READ,PV8READ,PV9READ,PV10READ)\n\n# create a separate table of all plausible values for SCIE\nsci_cols &lt;- stu_qqq_SG %&gt;%\n  select(PV1SCIE,PV2SCIE,PV3SCIE,PV4SCIE,PV5SCIE,\n         PV6SCIE,PV7SCIE,PV8SCIE,PV9SCIE,PV10SCIE)\n\n# create a character vector to store mappings for each school type\nschool_map &lt;- c(\"SGP01\" = \"Public/Secondary\",\n                \"SGP02\" = \"Public/Post-secondary\",\n                \"SGP03\" = \"Private/Secondary\",\n                \"SGP97\" = \"Undisclosed\")\n\n# create a new table stu_sg_data that takes data from stu_qqq_SG\nstu_sg_data &lt;- stu_qqq_SG %&gt;%\n  # change 1 and 2 labels to F and M for better readability\n  mutate(ST004D01T = \n           ifelse(ST004D01T == '1', 'F', \n                  ifelse(ST004D01T == '2', 'M', ST004D01T)),\n  # create SCHOOL column to label school type\n         SCHOOL = school_map[STRATUM],\n  # create new columns containing average values of PVs from each subject\n         MATH_PV_AVG = rowMeans(math_cols),\n         READ_PV_AVG = rowMeans(read_cols),\n         SCI_PV_AVG = rowMeans(sci_cols)) %&gt;%\n  # rename ST004D01T column name from question number to GENDER\n  rename(\"GENDER\" = \"ST004D01T\") %&gt;%\n  # create new columns containing average values of PVs from each subject\n  select(SCHOOL, GENDER, ESCS,\n         MATH_PV_AVG, READ_PV_AVG, SCI_PV_AVG)\n\nIn the original submission, the classmate binned the ESCS index by assigning a percentage score to each index. An alternative method is to use the summary statistics to determine the breaks in each bin. We can view the summary statistics using the summary() function.\n\nsummary(stu_qqq_SG$ESCS)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n-3.5488 -0.2327  0.4817  0.2904  0.9036  3.2780      47 \n\n\nUsing the results of the summary statistics above, we can make further changes to the analytical data:\n\nstu_sg_data &lt;- stu_sg_data %&gt;%\n  mutate(ESCS_binned = \n           case_when(\n           ESCS &gt;= -3.5488 & ESCS &lt; -0.2327 ~ \"Low\",\n           ESCS &gt;= -0.2327 & ESCS &lt; 0.4817 ~ \"Lower-Middle\",\n           ESCS &gt;= 0.4817 & ESCS &lt; 0.9036 ~ \"Upper-Middle\",\n           ESCS &gt;= 0.9036 & ESCS &lt;= 3.2780 ~ \"Upper\")) %&gt;%\n  select(SCHOOL, GENDER, ESCS_binned,\n         MATH_PV_AVG, READ_PV_AVG, SCI_PV_AVG)"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#check-for-missing-values",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#check-for-missing-values",
    "title": "Take-home Exercise 02 - DataVis Makeover",
    "section": "3.2. Check for Missing Values",
    "text": "3.2. Check for Missing Values\nNow that we have the cleaned data set, we will check for missing values using the following code:\n\ncolSums(is.na(stu_sg_data))\n\n     SCHOOL      GENDER ESCS_binned MATH_PV_AVG READ_PV_AVG  SCI_PV_AVG \n          0           0          47           0           0           0 \n\n\nIt is observed that 47 records from ESCS_binned is missing, which accounts for 0.7% of the total data points available."
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#distribution-of-performance-on-each-subject",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#distribution-of-performance-on-each-subject",
    "title": "Take-home Exercise 02 - DataVis Makeover",
    "section": "4.1. Distribution of Performance on Each subject",
    "text": "4.1. Distribution of Performance on Each subject\n\nOriginalProposed ChangeFinishing Touches\n\n\n\n\n\n\n\n\n\nWhat’s great\n\n\n\n\nUsing a histogram to analyse the distribution of scores for each subject is accurate.\nEach plot is created in a very structured and clear manner.\n\n\n\n\n\n\n\n\n\nWhat can be improved\n\n\n\n\nStandardise the x- and y-axes using coord_cartesian() for better comparison of the height and width of each distribution.\nThe additional vertical lines denoting first and third quartile and median appear to be distracting on the plot and does not provide much analytical insight. Naturally the frequency distribution would show where most of the data points lie.\nLastly, the arrangement of the plots do not allow a clear comparison of each subject’s score distribution.\n\n\n\n\n\nIn this proposed plot, the following changes are made:\n\nWe use the coord_cartesian() function to set the same x- and y-axes limits such that all three graphs are plotted to the same scale. This ensures that and visual comparisons made regarding the distribution and height and spread of the plot are accurate.\nInstead of displaying the vertical lines for first and third quartile, the proposed plot includes vertical lines for mean and median. The reason for choosing mean and median to display on the plot is that the relative position of mean to median (and vice versa) gives us an insight into the skewness of the data. In this plot, the mean and median values are not denoted as we can visually compare the positions of the mean and median across the three graphs due to the standardised x- and y-axes limits.\nLastly, the layout for the three graphs is changed for easier comparison. Each graph representing one subject is given its own colour fill to draw a better distinction between each graph.\n\n\n\nWhere magic happens\nmath &lt;- ggplot(data = stu_sg_data,\n               aes(x = MATH_PV_AVG)) +\n  geom_histogram(bins=15,\n                 color = \"grey40\",\n                 fill=\"mistyrose2\",\n                 linewidth = 0.5) +\n  geom_vline(xintercept = median(stu_sg_data$MATH_PV_AVG),\n             color = \"darkred\",\n             lwd = 1) +\n  annotate(\"text\",\n           x = median(stu_sg_data$MATH_PV_AVG),  \n           y = 1350,  \n           label = \"Median\",\n           color = \"darkred\",\n           size = 2.5,\n           vjust = 1.,  \n           hjust = -0.1) +\n  geom_vline(xintercept = mean(stu_sg_data$MATH_PV_AVG),\n             color = \"darkgreen\",\n             lwd = 1) +\n  annotate(\"text\",\n           x = mean(stu_sg_data$MATH_PV_AVG),  \n           y = 1350,  \n           label = \"Mean\",\n           color = \"darkgreen\",\n           size = 2.5,\n           vjust = 1.,  \n           hjust = 1.1) +\n  coord_cartesian(ylim = c(0, 1400),\n                  xlim = c(100, 900))\n\nread &lt;- ggplot(data = stu_sg_data,\n               aes(x = READ_PV_AVG)) +\n  geom_histogram(bins=15,\n                 color = \"grey40\",\n                 fill=\"azure2\",\n                 linewidth = 0.5) +\n  geom_vline(xintercept = median(stu_sg_data$READ_PV_AVG),\n             color = \"darkred\",\n             lwd = 1) +\n  annotate(\"text\",\n           x = median(stu_sg_data$READ_PV_AVG),  \n           y = 1450,  \n           label = \"Median\",\n           color = \"darkred\", \n           size = 2.5,\n           vjust = 1.,  \n           hjust = -0.1) +\n  geom_vline(xintercept = mean(stu_sg_data$READ_PV_AVG),\n             color = \"darkgreen\",\n             lwd = 1) +\n  annotate(\"text\",\n           x = mean(stu_sg_data$READ_PV_AVG),  \n           y = 1450,  \n           label = \"Mean\",\n           color = \"darkgreen\",\n           size = 2.5,\n           vjust = 1.,  \n           hjust = 1.1) +\n  coord_cartesian(ylim = c(0, 1400),\n                  xlim = c(100, 900))\n\nsci &lt;- ggplot(data = stu_sg_data,\n               aes(x = SCI_PV_AVG)) +\n  geom_histogram(bins=15,\n                 color = \"grey40\",\n                 fill=\"lightyellow1\",\n                 linewidth = 0.5) +\n  geom_vline(xintercept = median(stu_sg_data$SCI_PV_AVG),\n             color = \"darkred\",\n             lwd = 1) +\n  annotate(\"text\",\n           x = median(stu_sg_data$SCI_PV_AVG),  \n           y = 1400,  \n           label = \"Median\",\n           color = \"darkred\",\n           size = 2.5,\n           vjust = 1.,  \n           hjust = -0.1) +\n  geom_vline(xintercept = mean(stu_sg_data$SCI_PV_AVG),\n             color = \"darkgreen\",\n             lwd = 1) +\n  annotate(\"text\",\n           x = mean(stu_sg_data$SCI_PV_AVG),  \n           y = 1400,  \n           label = \"Mean\",\n           color = \"darkgreen\",\n           size = 2.5,\n           vjust = 1.,  \n           hjust = 1.1) +\n  coord_cartesian(ylim = c(0, 1400),\n                  xlim = c(100, 900)) \n\nmath / read / sci\n\n\n\n\n\n\n\nWe make further improvements to the proposed plot by improving the aesthetics:\n\nThe x- and y-axes labels are updated to reflect what the respective values represent.\nThe theme is set to theme_classic(). This is my personal preference as I find the theme to be clean and tidy.\nA title is added to each plot to reflect the respective subject, and an overall graph title is added.\n\n\n\nWhere magic happens\nmath &lt;- ggplot(data = stu_sg_data,\n               aes(x = MATH_PV_AVG)) +\n  geom_histogram(bins=15,\n                 color = \"grey40\",\n                 fill=\"mistyrose2\",\n                 linewidth = 0.5) +\n  geom_vline(xintercept = median(stu_sg_data$MATH_PV_AVG),\n             color = \"darkred\",\n             lwd = 1) +\n  annotate(\"text\",\n           x = median(stu_sg_data$MATH_PV_AVG),  \n           y = 1350,  \n           label = \"Median\",\n           color = \"darkred\",\n           size = 2.5,\n           vjust = 1.,  \n           hjust = -0.1) +\n  geom_vline(xintercept = mean(stu_sg_data$MATH_PV_AVG),\n             color = \"darkgreen\",\n             lwd = 1) +\n  annotate(\"text\",\n           x = mean(stu_sg_data$MATH_PV_AVG),  \n           y = 1350,  \n           label = \"Mean\",\n           color = \"darkgreen\",\n           size = 2.5,\n           vjust = 1.,  \n           hjust = 1.1) +\n  coord_cartesian(ylim = c(0, 1400),\n                  xlim = c(100, 900)) + \n  ylab(\"Frequency\") +\n  xlab(\"Average Plausive Value\") +\n  theme_classic(base_size=8) +\n  ggtitle(\"Maths\")\n\nread &lt;- ggplot(data = stu_sg_data,\n               aes(x = READ_PV_AVG)) +\n  geom_histogram(bins=15,\n                 color = \"grey40\",\n                 fill=\"azure2\",\n                 linewidth = 0.5) +\n  geom_vline(xintercept = median(stu_sg_data$READ_PV_AVG),\n             color = \"darkred\",\n             lwd = 1) +\n  annotate(\"text\",\n           x = median(stu_sg_data$READ_PV_AVG),  \n           y = 1450,  \n           label = \"Median\",\n           color = \"darkred\", \n           size = 2.5,\n           vjust = 1.,  \n           hjust = -0.1) +\n  geom_vline(xintercept = mean(stu_sg_data$READ_PV_AVG),\n             color = \"darkgreen\",\n             lwd = 1) +\n  annotate(\"text\",\n           x = mean(stu_sg_data$READ_PV_AVG),  \n           y = 1450,  \n           label = \"Mean\",\n           color = \"darkgreen\",\n           size = 2.5,\n           vjust = 1.,  \n           hjust = 1.1) +\n  coord_cartesian(ylim = c(0, 1400),\n                  xlim = c(100, 900)) + \n  ylab(\"Frequency\") +\n  xlab(\"Average Plausive Value\") +\n  theme_classic(base_size=8) +\n  ggtitle(\"Reading\")\n\nsci &lt;- ggplot(data = stu_sg_data,\n               aes(x = SCI_PV_AVG)) +\n  geom_histogram(bins=15,\n                 color = \"grey40\",\n                 fill=\"lightyellow1\",\n                 linewidth = 0.5) +\n  geom_vline(xintercept = median(stu_sg_data$SCI_PV_AVG),\n             color = \"darkred\",\n             lwd = 1) +\n  annotate(\"text\",\n           x = median(stu_sg_data$SCI_PV_AVG),  \n           y = 1400,  \n           label = \"Median\",\n           color = \"darkred\",\n           size = 2.5,\n           vjust = 1.,  \n           hjust = -0.1) +\n  geom_vline(xintercept = mean(stu_sg_data$SCI_PV_AVG),\n             color = \"darkgreen\",\n             lwd = 1) +\n  annotate(\"text\",\n           x = mean(stu_sg_data$SCI_PV_AVG),  \n           y = 1400,  \n           label = \"Mean\",\n           color = \"darkgreen\",\n           size = 2.5,\n           vjust = 1.,  \n           hjust = 1.1) +\n  coord_cartesian(ylim = c(0, 1400),\n                  xlim = c(100, 900)) + \n  ylab(\"Frequency\") +\n  xlab(\"Average Plausive Value\") +\n  theme_classic(base_size=8) +\n  ggtitle(\"Science\")\n\n(math / read / sci) + plot_annotation(\n  title = 'Distribution of Performance by Subject')"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#school-type-and-performance-by-subject",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#school-type-and-performance-by-subject",
    "title": "Take-home Exercise 02 - DataVis Makeover",
    "section": "4.2. School Type and Performance by Subject",
    "text": "4.2. School Type and Performance by Subject\n\nOriginalProposed ChangeFinishing Touches\n\n\n\n\n\n\n\n\n\nWhat’s great\n\n\n\n\nUsing a boxplot to analyse the distribution of scores for each subject helps to display a clear comparison in performance by school type.\nUse of the notch in the boxplot makes visualising the median between box plots easier.\nThe side-by-side arrangement of the plots make it easy for comparisons to be made.\n\n\n\n\n\n\n\n\n\nWhat can be improved\n\n\n\n\nStandardise the x- and y-axes using coord_cartesian() for better comparison of the height and width of each distribution.\nThe y-axis labels do not show that the values correspond to Average Plausible Values, instead it only indicates the subject.\n\n\n\n\n\nIn this proposed plot, the following changes are made:\n\nWe use the coord_cartesian() function to set the same x- and y-axes limits such that all three graphs are plotted to the same scale. This ensures that and visual comparisons made regarding the distribution and height and spread of the plot are accurate.\nThe y-axis labels are also updated to reflect “Average Plausible Value”, which is what the values in the y-axis represent.\nTo main consistency with the previous plot, we use the same fill colour to distinguish each subject.\n\n\n\nWhere magic happens\nmath_sch &lt;- ggplot(data = stu_sg_data,\n               aes(x = SCHOOL,\n                   y = MATH_PV_AVG)) +\n  geom_boxplot(notch = TRUE, \n               color = \"grey40\",\n               fill=\"mistyrose2\") +\n  ylab(\"Average Plausible Value\") +\n  coord_cartesian(ylim = c(150, 850))\n\nread_sch &lt;- ggplot(data = stu_sg_data,\n               aes(x = SCHOOL,\n                   y = READ_PV_AVG)) +\n  geom_boxplot(notch = TRUE,\n               color = \"grey40\",\n               fill=\"azure2\") +\n  ylab(\"Average Plausible Value\") +\n  coord_cartesian(ylim = c(150, 850))\n\nsci_sch &lt;- ggplot(data = stu_sg_data,\n               aes(x = SCHOOL,\n                   y = SCI_PV_AVG)) +\n  geom_boxplot(notch = TRUE,\n               color = \"grey40\",\n               fill=\"lightyellow1\") +\n  ylab(\"Average Plausible Value\") +\n  coord_cartesian(ylim = c(150, 850)) \n\nmath_sch | read_sch | sci_sch\n\n\n\n\n\n\n\nWe make further improvements to the proposed plot by improving the aesthetics:\n\nTo maintain consistency with the previous plot, the theme is set to theme_classic().\nA title is added to each plot to reflect the respective subject, and an overall graph title is added.\n\n\n\nWhere magic happens\nmath_sch &lt;- ggplot(data = stu_sg_data,\n               aes(x = SCHOOL,\n                   y = MATH_PV_AVG)) +\n  geom_boxplot(notch = TRUE, \n               color = \"grey40\",\n               fill=\"mistyrose2\",\n               median.col = \"darkred\") +\n  ylab(\"Average Plausible Value\") +\n  coord_cartesian(ylim = c(150, 850))  + \n  ggtitle(\"Maths\") +\n  theme_classic(base_size = 8)\n\nread_sch &lt;- ggplot(data = stu_sg_data,\n               aes(x = SCHOOL,\n                   y = READ_PV_AVG)) +\n  geom_boxplot(notch = TRUE,\n               color = \"grey40\",\n               fill=\"azure2\") +\n  ylab(\"Average Plausible Value\") +\n  coord_cartesian(ylim = c(150, 850)) + \n  ggtitle(\"Reading\") +\n  theme_classic(base_size = 8)\n\nsci_sch &lt;- ggplot(data = stu_sg_data,\n               aes(x = SCHOOL,\n                   y = SCI_PV_AVG)) +\n  geom_boxplot(notch = TRUE,\n               color = \"grey40\",\n               fill=\"lightyellow1\") +\n  ylab(\"Average Plausible Value\") +\n  coord_cartesian(ylim = c(150, 850)) + \n  ggtitle(\"Science\") +\n  theme_classic(base_size = 8)\n\n(math_sch | read_sch | sci_sch) + plot_annotation(\n  title = 'Relationship Between School and Performance in Each Subject')"
  },
  {
    "objectID": "take_home_ex/take_home_ex02/take_home_ex02.html#socioeconomic-status-and-performance",
    "href": "take_home_ex/take_home_ex02/take_home_ex02.html#socioeconomic-status-and-performance",
    "title": "Take-home Exercise 02 - DataVis Makeover",
    "section": "4.3. Socioeconomic Status and Performance",
    "text": "4.3. Socioeconomic Status and Performance\n\nOriginalProposed ChangeFinishing Touches\n\n\n\n\n\n\n\n\n\nWhat’s great\n\n\n\n\nUsing a boxplot to analyse the distribution of scores for each subject helps to display a clear comparison in performance by socioeconomic status type.\nUse of the notch in the boxplot makes visualising the median between box plots easier.\nThe side-by-side arrangement of the plots make it easy for comparisons to be made.\n\n\n\n\n\n\n\n\n\nWhat can be improved\n\n\n\n\nStandardise the x- and y-axes using coord_cartesian() for better comparison of the height and width of each distribution.\nThe y-axis labels do not show that the values correspond to Average Plausible Values, instead it only indicates the subject.\nSocioeconomic status bins should be arranged in ascending order (Low, Lower-Middle, Upper-Middle, High) for better viewing experience.\n\n\n\n\n\nIn this proposed plot, the following changes are made:\n\nWe use the coord_cartesian() function to set the same x- and y-axes limits such that all three graphs are plotted to the same scale. This ensures that and visual comparisons made regarding the distribution and height and spread of the plot are accurate.\nThe x- and y-axes labels are also updated to improve readability of the graph.\nTo main consistency with the previous plot, we use the same fill colour to distinguish each subject.\nThe ESCS_binned column is amended to reflect the correct ascending order of the categories.\n\n\n\nWhere magic happens\n# create new column defining grouping sequence\nstu_sg_data$ESCS_binned &lt;- factor(stu_sg_data$ESCS_binned,\n                            levels = c(\"Low\", \"Lower-Middle\", \"Upper-Middle\", \"Upper\"))\n\nmath_escs &lt;- ggplot(data = na.omit(stu_sg_data),\n               aes(x = ESCS_binned,\n                   y = MATH_PV_AVG)) +\n  geom_boxplot(notch = TRUE, \n               color = \"grey40\",\n               fill=\"mistyrose2\") +\n  xlab(\"Socioeconomic Status\") +\n  ylab(\"Average Plausible Value\") +\n  coord_cartesian(ylim = c(150, 850))\n\nread_escs &lt;- ggplot(data = na.omit(stu_sg_data),\n               aes(x = ESCS_binned,\n                   y = READ_PV_AVG)) +\n  geom_boxplot(notch = TRUE,\n               color = \"grey40\",\n               fill=\"azure2\") +\n  xlab(\"Socioeconomic Status\") +\n  ylab(\"Average Plausible Value\") +\n  coord_cartesian(ylim = c(150, 850))\n\nsci_escs &lt;- ggplot(data = na.omit(stu_sg_data),\n               aes(x = ESCS_binned,\n                   y = SCI_PV_AVG)) +\n  geom_boxplot(notch = TRUE,\n               color = \"grey40\",\n               fill=\"lightyellow1\") +\n  xlab(\"Socioeconomic Status\") +\n  ylab(\"Average Plausible Value\") +\n  coord_cartesian(ylim = c(150, 850)) \n\nmath_escs | read_escs | sci_escs\n\n\n\n\n\n\n\nWe make further improvements to the proposed plot by improving the aesthetics:\n\nTo maintain consistency with the previous plot, the theme is set to theme_classic().\nA title is added to each plot to reflect the respective subject, and an overall graph title is added.\n\n\n\nWhere magic happens\nmath_escs &lt;- ggplot(data = na.omit(stu_sg_data),\n               aes(x = ESCS_binned,\n                   y = MATH_PV_AVG)) +\n  geom_boxplot(notch = TRUE, \n               color = \"grey40\",\n               fill=\"mistyrose2\") +\n  xlab(\"Socioeconomic Status\") +\n  ylab(\"Average Plausible Value\") +\n  coord_cartesian(ylim = c(150, 850)) + \n  ggtitle(\"Maths\") +\n  theme_classic(base_size = 8) + \n  theme(axis.text.x = element_text(size = 5))\n\nread_escs &lt;- ggplot(data = na.omit(stu_sg_data),\n               aes(x = ESCS_binned,\n                   y = READ_PV_AVG)) +\n  geom_boxplot(notch = TRUE,\n               color = \"grey40\",\n               fill=\"azure2\") +\n  xlab(\"Socioeconomic Status\") +\n  ylab(\"Average Plausible Value\") +\n  coord_cartesian(ylim = c(150, 850)) + \n  ggtitle(\"Read\") +\n  theme_classic(base_size = 8) + \n  theme(axis.text.x = element_text(size = 5))\n\nsci_escs &lt;- ggplot(data = na.omit(stu_sg_data),\n               aes(x = ESCS_binned,\n                   y = SCI_PV_AVG)) +\n  geom_boxplot(notch = TRUE,\n               color = \"grey40\",\n               fill=\"lightyellow1\") +\n  xlab(\"Socioeconomic Status\") +\n  ylab(\"Average Plausible Value\") +\n  coord_cartesian(ylim = c(150, 850)) + \n  ggtitle(\"Science\") +\n  theme_classic(base_size = 8) + \n  theme(axis.text.x = element_text(size = 5))\n\n(math_escs | read_escs | sci_escs) + plot_annotation(\n  title = 'Relationship Between Socioeconomic Status and Performance in Each Subject')"
  },
  {
    "objectID": "take_home_ex/take_home_ex03/take_home_ex03.html",
    "href": "take_home_ex/take_home_ex03/take_home_ex03.html",
    "title": "How Is Climate Change Affecting Singapore’s Temperature?",
    "section": "",
    "text": "Note\n\n\n\nFinal edits were made on 19 February 2024 to the aesthetics of plots found in section 4.3 and 4.4 to ensure plot titles and other text can be seen clearly. No other changes were made."
  },
  {
    "objectID": "take_home_ex/take_home_ex03/take_home_ex03.html#loading-relevant-packages",
    "href": "take_home_ex/take_home_ex03/take_home_ex03.html#loading-relevant-packages",
    "title": "How Is Climate Change Affecting Singapore’s Temperature?",
    "section": "2.1. Loading Relevant Packages",
    "text": "2.1. Loading Relevant Packages\nWe will load tidyverse where the ggplot2 package can be found, and patchwork. We will use ggplot2 to plot the statistical graphs, and patchwork to create composite graphs.\n\npacman::p_load(tidyverse, patchwork, stringr,\n               ggiraph, DT, crosstalk, plotly)"
  },
  {
    "objectID": "take_home_ex/take_home_ex03/take_home_ex03.html#import-data",
    "href": "take_home_ex/take_home_ex03/take_home_ex03.html#import-data",
    "title": "How Is Climate Change Affecting Singapore’s Temperature?",
    "section": "2.2. Import Data",
    "text": "2.2. Import Data\nWe will use the read_csv() function from the readr package found in tidyverse to load each dataset into R:\n\nsep1986 &lt;- read_csv(\"data/DAILYDATA_S23_198609.csv\")\nsep1993 &lt;- read_csv(\"data/DAILYDATA_S23_199309.csv\")\nsep2003 &lt;- read_csv(\"data/DAILYDATA_S23_200309.csv\")\nsep2013 &lt;- read_csv(\"data/DAILYDATA_S23_201309.csv\")\nsep2023 &lt;- read_csv(\"data/DAILYDATA_S23_202309.csv\")\n\n\nglimpse(sep1986)\n\nRows: 30\nColumns: 13\n$ Station                         &lt;chr&gt; \"Tengah\", \"Tengah\", \"Tengah\", \"Tengah\"…\n$ Year                            &lt;dbl&gt; 1986, 1986, 1986, 1986, 1986, 1986, 19…\n$ Month                           &lt;dbl&gt; 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,…\n$ Day                             &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,…\n$ `Daily Rainfall Total (mm)`     &lt;dbl&gt; 1.0, 0.0, 12.0, 0.0, 20.4, 0.0, 1.3, 7…\n$ `Highest 30 Min Rainfall (mm)`  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `Highest 60 Min Rainfall (mm)`  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `Highest 120 Min Rainfall (mm)` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `Mean Temperature`              &lt;dbl&gt; 26.5, 27.2, 24.9, 26.8, 26.1, 26.6, 27…\n$ `Maximum Temperature`           &lt;dbl&gt; 33.3, 33.4, 26.9, 31.2, 30.5, 31.1, 32…\n$ `Minimum Temperature`           &lt;dbl&gt; 23.5, 22.7, 23.1, 22.7, 22.5, 24.1, 24…\n$ `Mean Wind Speed (km/h)`        &lt;dbl&gt; 11.7, 10.7, 10.4, 10.9, 7.4, 12.0, 13.…\n$ `Max Wind Speed (km/h)`         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\nglimpse(sep1993)\n\nRows: 30\nColumns: 13\n$ Station                         &lt;chr&gt; \"Tengah\", \"Tengah\", \"Tengah\", \"Tengah\"…\n$ Year                            &lt;dbl&gt; 1993, 1993, 1993, 1993, 1993, 1993, 19…\n$ Month                           &lt;dbl&gt; 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,…\n$ Day                             &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,…\n$ `Daily Rainfall Total (mm)`     &lt;dbl&gt; 0.6, 0.0, 7.8, 17.0, 5.8, 40.3, 0.0, 3…\n$ `Highest 30 Min Rainfall (mm)`  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `Highest 60 Min Rainfall (mm)`  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `Highest 120 Min Rainfall (mm)` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `Mean Temperature`              &lt;dbl&gt; 26.7, 27.6, 26.9, 26.2, 25.2, 25.2, 26…\n$ `Maximum Temperature`           &lt;dbl&gt; 32.7, 32.6, 32.1, 32.0, 31.9, 31.5, 31…\n$ `Minimum Temperature`           &lt;dbl&gt; 22.5, 23.9, 22.7, 23.4, 22.8, 22.0, 22…\n$ `Mean Wind Speed (km/h)`        &lt;dbl&gt; 6.7, 6.3, 10.0, 5.5, 5.6, 6.8, 10.1, 6…\n$ `Max Wind Speed (km/h)`         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\nglimpse(sep2003)\n\nRows: 30\nColumns: 13\n$ Station                         &lt;chr&gt; \"Tengah\", \"Tengah\", \"Tengah\", \"Tengah\"…\n$ Year                            &lt;dbl&gt; 2003, 2003, 2003, 2003, 2003, 2003, 20…\n$ Month                           &lt;dbl&gt; 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,…\n$ Day                             &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,…\n$ `Daily Rainfall Total (mm)`     &lt;dbl&gt; 11.0, 5.0, 0.0, 0.2, 0.0, 0.0, 7.9, 15…\n$ `Highest 30 Min Rainfall (mm)`  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `Highest 60 Min Rainfall (mm)`  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `Highest 120 Min Rainfall (mm)` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `Mean Temperature`              &lt;dbl&gt; 27.9, 25.2, 27.4, 27.4, 27.1, 27.8, 28…\n$ `Maximum Temperature`           &lt;dbl&gt; 34.0, 29.3, 33.0, 32.1, 32.2, 33.0, 33…\n$ `Minimum Temperature`           &lt;dbl&gt; 23.1, 21.4, 23.3, 23.6, 23.4, 24.1, 24…\n$ `Mean Wind Speed (km/h)`        &lt;dbl&gt; 8.0, 9.7, 8.8, 11.4, 8.4, 9.5, 11.1, 1…\n$ `Max Wind Speed (km/h)`         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\nglimpse(sep2013)\n\nRows: 30\nColumns: 13\n$ Station                         &lt;chr&gt; \"Tengah\", \"Tengah\", \"Tengah\", \"Tengah\"…\n$ Year                            &lt;dbl&gt; 2013, 2013, 2013, 2013, 2013, 2013, 20…\n$ Month                           &lt;dbl&gt; 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,…\n$ Day                             &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,…\n$ `Daily Rainfall Total (mm)`     &lt;dbl&gt; 0.0, 5.2, 8.7, 6.3, 31.8, 28.8, 2.8, 0…\n$ `Highest 30 Min Rainfall (mm)`  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `Highest 60 Min Rainfall (mm)`  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `Highest 120 Min Rainfall (mm)` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `Mean Temperature`              &lt;dbl&gt; 27.2, 27.0, 26.7, 26.2, 25.8, 26.5, 25…\n$ `Maximum Temperature`           &lt;dbl&gt; 31.7, 32.4, 31.2, 30.2, 29.0, 30.7, 29…\n$ `Minimum Temperature`           &lt;dbl&gt; 23.7, 23.4, 23.8, 23.6, 22.9, 21.8, 22…\n$ `Mean Wind Speed (km/h)`        &lt;dbl&gt; 9.1, 8.9, 5.5, 5.1, 8.6, 7.2, 8.0, 8.2…\n$ `Max Wind Speed (km/h)`         &lt;dbl&gt; 35.3, 33.5, 18.4, 16.6, 37.1, 22.3, 22…\n\nglimpse(sep2023)\n\nRows: 30\nColumns: 13\n$ Station                         &lt;chr&gt; \"Tengah\", \"Tengah\", \"Tengah\", \"Tengah\"…\n$ Year                            &lt;dbl&gt; 2023, 2023, 2023, 2023, 2023, 2023, 20…\n$ Month                           &lt;dbl&gt; 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,…\n$ Day                             &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,…\n$ `Daily Rainfall Total (mm)`     &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 21.2, 0.2, 0.…\n$ `Highest 30 min Rainfall (mm)`  &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 2.8, 0.2, 0.0…\n$ `Highest 60 min Rainfall (mm)`  &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.2, 0.0…\n$ `Highest 120 min Rainfall (mm)` &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 8.7, 0.8, 0.0…\n$ `Mean Temperature`              &lt;dbl&gt; 28.5, 28.8, 29.2, 29.3, 29.0, 26.5, 27…\n$ `Maximum Temperature`           &lt;dbl&gt; 32.3, 33.2, 32.5, 32.8, 32.9, 30.6, 32…\n$ `Minimum Temperature`           &lt;dbl&gt; 25.0, 23.9, 26.6, 27.0, 26.5, 24.3, 24…\n$ `Mean Wind Speed (km/h)`        &lt;dbl&gt; 7.5, 6.7, 8.7, 9.7, 8.4, 6.1, 5.1, 7.4…\n$ `Max Wind Speed (km/h)`         &lt;dbl&gt; 27.0, 23.6, 30.1, 27.9, 23.4, 22.9, 16…\n\n\nUsing glimpse() to view one of the data sets, we can see that each data set contains the daily rainfall, temperature and wind speed data of the selected weather station, month, and year."
  },
  {
    "objectID": "take_home_ex/take_home_ex03/take_home_ex03.html#selecting-relevant-features",
    "href": "take_home_ex/take_home_ex03/take_home_ex03.html#selecting-relevant-features",
    "title": "How Is Climate Change Affecting Singapore’s Temperature?",
    "section": "3.1. Selecting Relevant Features",
    "text": "3.1. Selecting Relevant Features\nAs we will only be analysing temperature data and trends in this exercise, we will extract the required fields from the imported data set. Using the sep1986 dataset as an example, we will extract only the Year, Month, Day, and Mean, Minimum and Maximum Temperature. We will change the data type of Year and Month, and Day from dbl to chr to avoid them being read as integers. In addition, we will add a preceding 0 for Days 1 to 9 for sorting purposes.\n\nsep1986 &lt;- sep1986 %&gt;%\n  select('Year','Month','Day',\n         'Mean Temperature', 'Maximum Temperature', 'Minimum Temperature') %&gt;%\n  rename('Mean_Temp' = 'Mean Temperature',\n         'Max_Temp' = 'Maximum Temperature',\n         'Min_Temp' = 'Minimum Temperature') %&gt;%\n  mutate(Year = as.character(Year),\n         Month = as.character(Month),\n         Day = str_pad(as.character(Day), width = 2, pad = \"0\"))\n\nWe will repeat the same steps for the remaining four data sets.\n\n\nCodes here\nsep1993 &lt;- sep1993 %&gt;%\n  select('Year','Month','Day',\n         'Mean Temperature', 'Maximum Temperature', 'Minimum Temperature') %&gt;%\n  rename('Mean_Temp' = 'Mean Temperature',\n         'Max_Temp' = 'Maximum Temperature',\n         'Min_Temp' = 'Minimum Temperature') %&gt;%\n  mutate(Year = as.character(Year),\n         Month = as.character(Month),\n         Day = str_pad(as.character(Day), width = 2, pad = \"0\"))\n\nsep2003 &lt;- sep2003 %&gt;%\n  select('Year','Month','Day',\n         'Mean Temperature', 'Maximum Temperature', 'Minimum Temperature') %&gt;%\n  rename('Mean_Temp' = 'Mean Temperature',\n         'Max_Temp' = 'Maximum Temperature',\n         'Min_Temp' = 'Minimum Temperature') %&gt;%\n  mutate(Year = as.character(Year),\n         Month = as.character(Month),\n         Day = str_pad(as.character(Day), width = 2, pad = \"0\"))\n\nsep2013 &lt;- sep2013 %&gt;%\n  select('Year','Month','Day',\n         'Mean Temperature', 'Maximum Temperature', 'Minimum Temperature') %&gt;%\n  rename('Mean_Temp' = 'Mean Temperature',\n         'Max_Temp' = 'Maximum Temperature',\n         'Min_Temp' = 'Minimum Temperature') %&gt;%\n  mutate(Year = as.character(Year),\n         Month = as.character(Month),\n         Day = str_pad(as.character(Day), width = 2, pad = \"0\"))\n\nsep2023 &lt;- sep2023 %&gt;%\n  select('Year','Month','Day',\n         'Mean Temperature', 'Maximum Temperature', 'Minimum Temperature') %&gt;%\n  rename('Mean_Temp' = 'Mean Temperature',\n         'Max_Temp' = 'Maximum Temperature',\n         'Min_Temp' = 'Minimum Temperature') %&gt;%\n  mutate(Year = as.character(Year),\n         Month = as.character(Month),\n         Day = str_pad(as.character(Day), width = 2, pad = \"0\"))"
  },
  {
    "objectID": "take_home_ex/take_home_ex03/take_home_ex03.html#combine-into-one-table",
    "href": "take_home_ex/take_home_ex03/take_home_ex03.html#combine-into-one-table",
    "title": "How Is Climate Change Affecting Singapore’s Temperature?",
    "section": "3.2. Combine Into One Table",
    "text": "3.2. Combine Into One Table\nFor the purpose of this exercise, we will combine the five data sets into one tibble data frame using the bind_rows() function from the dplyr package. bind_rows() is chosen over bind_cols() as we want to group the data by its respective columns.\n\ntengah_sep &lt;- bind_rows(sep1986, sep1993, sep2003, sep2013, sep2023)"
  },
  {
    "objectID": "take_home_ex/take_home_ex03/take_home_ex03.html#daily-mean-temperature",
    "href": "take_home_ex/take_home_ex03/take_home_ex03.html#daily-mean-temperature",
    "title": "How Is Climate Change Affecting Singapore’s Temperature?",
    "section": "4.1. Daily Mean Temperature",
    "text": "4.1. Daily Mean Temperature\nFirst, we will visualise the Daily Mean Temperature trend by year using the following code:\n\n\nCodes here\ntengah_sep$tooltip &lt;- c(paste0(\n  \"Day: \", tengah_sep$Day,\"-\",tengah_sep$Month,\"-\",tengah_sep$Year,\n  \"\\n Mean Temp: \", tengah_sep$Mean_Temp, \"°C\"))\n\nline &lt;- ggplot(data = tengah_sep,\n               aes(x = Day,\n                   y = Mean_Temp,\n                   group = Year,\n                   color = Year,\n                   data_id = Year)) +\n  geom_line_interactive(size = 1.2,\n                        alpha = 0.4) +\n  geom_point_interactive(aes(tooltip = tengah_sep$tooltip),\n                         fill = \"white\",\n                         size = 1,\n                         stroke = 1,\n                         shape = 21) +\n  theme_classic() +\n  ylab(\"Daily Mean Temperature (°C)\") +\n  xlab(\"Day of Month\") +\n  ggtitle(\"Daily Mean Temperature Recorded At Tengah Weather Station\",\n          subtitle = \"September 1986, 1993, 2003, 2013, 2023\") +\n  theme(plot.title = element_text(size = 10),\n        plot.subtitle = element_text(size = 8)) \n\ngirafe(ggobj = line, \n       width_svg = 8,\n       height_svg = 6 * 0.618,\n       options = list(\n         opts_hover(css = \"stroke-width: 2.5; opacity: 1;\"),\n         opts_hover_inv(css = \"stroke-width: 1;opacity:0.6;\")))\n\n\n\n\n\n\nIt can be observed from the graph that the daily mean temperature recorded at the Tengah weather station is generally higher in 2023 (purple line) and 2013 (blue line). This is in stark contrast to the daily mean temperatures recorded in 1986 (red line), where it is generally lower."
  },
  {
    "objectID": "take_home_ex/take_home_ex03/take_home_ex03.html#highlighting-data-points-from-the-same-year",
    "href": "take_home_ex/take_home_ex03/take_home_ex03.html#highlighting-data-points-from-the-same-year",
    "title": "How Is Climate Change Affecting Singapore’s Temperature?",
    "section": "4.2. Highlighting Data Points From The Same Year",
    "text": "4.2. Highlighting Data Points From The Same Year\n\n\nCodes here\ndaily_temp &lt;- ggplot(data = tengah_sep,\n               aes(x = Mean_Temp)) +\n  geom_dotplot_interactive(\n    aes(data_id = Year,\n        tooltip = tengah_sep$tooltip),\n    stackgroups = TRUE,\n    binwidth = 0.1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL) +\n  scale_x_continuous(breaks = seq(23, 30, by = 1)) +\n  theme_classic() +\n  xlab(\"Daily Mean Temperature (°C)\") +\n  ggtitle(\"Daily Mean Temperature Recorded At Tengah Weather Station\",\n          subtitle = \"September 1986, 1993, 2003, 2013, 2023\") +\n  theme(plot.title = element_text(size = 10),\n        plot.subtitle = element_text(size = 8),\n        axis.line.y = element_blank()) \n  \n\ngirafe(ggobj = daily_temp,\n       width_svg = 8,\n       height_svg = 6 * 0.618,\n       options = list(\n         opts_hover(css = \"fill:red;\"),\n         opts_hover_inv(css = \"opacity:0.4;\")))\n\n\n\n\n\n\nWe can make the same observation that higher daily mean temperatures are observed in 2013 and 2023 from the graph above as well. Many of the data points found on the higher end of the x-axis belong to 2013 and 2023, while many of the data points found on the lower end of the x-axis belong to 1986, 1993, and 2003.\nLet’s try to visualise the distribution of daily mean temperatures with each year occupying its own plot.\nFirst, we create a new column in each tibble data frame to contain the tooltip. The tooltip will contain the corresponding date and mean temperature recorded on the chosen data point. Using the sep1986 data frame as an example, we will use the following code chunk to create the tooltip and graph before storing it as an object to be used with the giraph() function.\n\nsep1986$tooltip &lt;- c(paste0(\n  \"Day: \", sep1986$Day,\"-\",sep1986$Month,\"-\",sep1986$Year,\n  \"\\n Mean Temp: \", sep1986$Mean_Temp, \"°C\"))\n\ndotplot86 &lt;- ggplot(data = sep1986,\n                    aes(x = Mean_Temp)) +\n  geom_dotplot_interactive(\n    aes(data_id = Day,\n        tooltip = sep1986$tooltip),\n    stackgroups = TRUE,\n    binwidth = 0.3,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL) +\n  coord_cartesian(xlim = c(23.5, 30)) +\n  xlab(\"1986 Daily Mean Temperature (°C)\") +\n  theme_classic() +\n  ggtitle(\"Daily Mean Temperature Recorded At Tengah Weather Station\",\n          subtitle = \"September 1986, 1993, 2003, 2013, 2023\") +\n  theme(plot.title = element_text(size = 4.8),\n        plot.subtitle = element_text(size = 4),\n        axis.title.x = element_text(size = 4.5),\n        axis.line.y = element_blank()) \n\nWe will repeat the above steps with the other data frames.\n\n\nCodes here\nsep1993$tooltip &lt;- c(paste0(\n  \"Day: \", sep1993$Day,\"-\",sep1993$Month,\"-\",sep1993$Year,\n  \"\\n Mean Temp: \", sep1993$Mean_Temp, \"°C\"))\n\ndotplot93 &lt;- ggplot(data = sep1993,\n                    aes(x = Mean_Temp)) +\n  geom_dotplot_interactive(\n    aes(data_id = Day,\n        tooltip = sep1993$tooltip),\n    stackgroups = TRUE,\n    binwidth = 0.3,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL) +\n  coord_cartesian(xlim = c(23.5, 30)) +\n  xlab(\"1993 Daily Mean Temperature (°C)\") +\n  theme_classic() +\n  theme(axis.title.x = element_text(size = 4.5),\n        axis.line.y = element_blank()) \n\nsep2003$tooltip &lt;- c(paste0(\n  \"Day: \", sep2003$Day,\"-\",sep2003$Month,\"-\",sep2003$Year,\n  \"\\n Mean Temp: \", sep2003$Mean_Temp, \"°C\"))\n\ndotplot03 &lt;- ggplot(data = sep2003,\n                    aes(x = Mean_Temp)) +\n  geom_dotplot_interactive(\n    aes(data_id = Day,\n        tooltip = sep2003$tooltip),\n    stackgroups = TRUE,\n    binwidth = 0.3,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL) +\n  coord_cartesian(xlim = c(23.5, 30)) +\n  xlab(\"2003 Daily Mean Temperature (°C)\") +\n  theme_classic() +\n  theme(axis.title.x = element_text(size = 4.5),\n        axis.line.y = element_blank()) \n\nsep2013$tooltip &lt;- c(paste0(\n  \"Day: \", sep2013$Day,\"-\",sep2013$Month,\"-\",sep2013$Year,\n  \"\\n Temp: \", sep2013$Mean_Temp, \"°C\"))\n\n\ndotplot13 &lt;- ggplot(data = sep2013,\n                    aes(x = Mean_Temp)) +\n  geom_dotplot_interactive(\n    aes(data_id = Day,\n        tooltip = sep2013$tooltip),\n    stackgroups = TRUE,\n    binwidth = 0.3,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL) +\n  coord_cartesian(xlim = c(23.5, 30)) +\n  xlab(\"2013 Daily Mean Temperature (°C)\") +\n  theme_classic() +\n  theme(axis.title.x = element_text(size = 4.5),\n        axis.line.y = element_blank()) \n\nsep2023$tooltip &lt;- c(paste0(\n  \"Day: \", sep2023$Day,\"-\",sep2023$Month,\"-\",sep2023$Year,\n  \"\\n Mean Temp: \", sep2023$Mean_Temp, \"°C\"))\n\n\ndotplot23 &lt;- ggplot(data = sep2023,\n                    aes(x = Mean_Temp)) +\n  geom_dotplot_interactive(\n    aes(data_id = Day,\n        tooltip = sep2023$tooltip),\n    stackgroups = TRUE,\n    binwidth = 0.3,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL) +\n  coord_cartesian(xlim = c(23.5, 30)) +\n  xlab(\"2023 Daily Mean Temperature (°C)\") +\n  theme_classic() +\n  theme(axis.title.x = element_text(size = 4.5),\n        axis.line.y = element_blank()) \n\ngirafe(code = print(dotplot86 + dotplot93 + dotplot03 + dotplot13 + dotplot23),\n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill:red;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n       ))\n\n\n\n\n\n\nFrom the plot above, we can see that the distribution of daily mean temperature has shifted from a range of 23°C to 28°C in 1986 to a range of 26°C to 30°C in 2023. This shows an increase in the daily mean temperatures recorded over the the same month per decade.\nHowever, there is no clear pattern in the temperature trend if we look at the day-of-month level of detail. For example, 28 September recorded the highest daily mean temperature in 2023 but the same day recorded mid-range daily mean temperatures in the preceding years."
  },
  {
    "objectID": "take_home_ex/take_home_ex03/take_home_ex03.html#confidence-interval-of-daily-mean-temperature",
    "href": "take_home_ex/take_home_ex03/take_home_ex03.html#confidence-interval-of-daily-mean-temperature",
    "title": "How Is Climate Change Affecting Singapore’s Temperature?",
    "section": "4.3. Confidence Interval of Daily Mean Temperature",
    "text": "4.3. Confidence Interval of Daily Mean Temperature\n\n\nCodes here\ntooltip &lt;- function(y, ymax, accuracy = 0.1) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"September mean temperature:\", mean, \"+/-\", sem)\n}\n\ngg_pt &lt;- ggplot(data = tengah_sep,\n                aes(x = Year)) +\n  stat_summary(aes(y = Mean_Temp,\n                   tooltip = after_stat(\n                     tooltip(y, ymax))),\n               fun.data = \"mean_se\",\n               geom = GeomInteractiveCol,\n               fill = \"rosybrown2\"\n               ) +\n  stat_summary(aes(y = Mean_Temp),\n               fun.data = mean_se,\n               geom = \"errorbar\", width = 0.2, linewidth = 0.2) +\n  ylab(\"Mean Temperature (°C)\") +\n  xlab(\"Year\") +\n  theme_classic() +\n  ggtitle(\"Confidence Interval of Daily Mean Temperature Recorded At Tengah Weather Station\",\n          subtitle = \"September 1986, 1993, 2003, 2013, 2023\") +\n  theme(plot.title = element_text(size = 10),\n        plot.subtitle = element_text(size = 8),\n        axis.title.x = element_text(size = 4.5)) \n\ngirafe(ggobj = gg_pt,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\nFrom the bar chart, we can see that the September mean temperature recorded at the Tengah weather station increased by 0.7°C from 2003 to 2013, and 0.9°C from 2013 to 2023 while the it remained relatively stable from 1986 to 1993 to 2003.\nThe small range of the error bar indicates small variability in the mean temperature recorded in September across the five selected years. This means that both the lowest and highest of the mean temperatures recorded increased at a similar pace."
  },
  {
    "objectID": "take_home_ex/take_home_ex03/take_home_ex03.html#confidence-interval-of-point-estimates",
    "href": "take_home_ex/take_home_ex03/take_home_ex03.html#confidence-interval-of-point-estimates",
    "title": "How Is Climate Change Affecting Singapore’s Temperature?",
    "section": "4.4. Confidence Interval of Point Estimates",
    "text": "4.4. Confidence Interval of Point Estimates\nLastly, we will visualise a confidence interval of point estimates according to the minimum, maximum and mean temperatures recorded at the Tengah weather station in September of the five selected years. In order to do it, we have to create a long data table using the following code:\n\ntengah_sep_long &lt;- pivot_longer(data = tengah_sep,\n                     cols = 4:6,\n                     names_to = \"Measurement\",\n                     values_to = \"Temperature\")\n\nNext, we create a table containing the summary statistics of each measurement type:\n\nsum_stat &lt;- tengah_sep_long %&gt;%\n  group_by(Measurement) %&gt;%\n  summarise(n = n(),\n            mean = mean(Temperature),\n            sd = sd(Temperature)) %&gt;%\n  mutate(se = sd/sqrt(n-1))\n\nLastly, we use the summary statistics to create the the plot that is linked to a data table displaying the details.\n\n\nCodes here\nshared_df = SharedData$new(sum_stat)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(data = shared_df) +\n                   geom_errorbar(aes(x=reorder(Measurement, -mean),\n                                     ymin=mean-2.58*se, \n                                     ymax=mean+2.58*se), \n                                 width=0.2, \n                                 colour=\"black\", \n                                 alpha=0.9, \n                                 size=0.5) +\n                    geom_point(aes(x=Measurement, \n                                   y=mean, \n                                   text = paste(\"Measurement:\", `Measurement`, \n                                                \"&lt;br&gt;N:\", `n`,\n                                                \"&lt;br&gt;Avg. Temp:\", round(mean, digits = 2),\n                                                \"&lt;br&gt;99% CI:[\", \n                                                round((mean-2.58*se), digits = 2), \",\",\n                                                round((mean+2.58*se), digits = 2),\"]\")),\n                               stat=\"identity\", \n                               color=\"red\", \n                               size = 1.5, \n                               alpha=1) + \n                   xlab(\"Measurement Type\") + \n                   ylab(\"Temperature (°C)\") + \n                   theme_classic() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1, size = 6),\n                     plot.title = element_text(size = 9.4),\n                     axis.text.y = element_text(size = 6),\n                     axis.title.x = element_text(size = 8),\n                     axis.title.y = element_text(size = 8)) +\n                   ggtitle(\"99% CI of Temperature &lt;br&gt;by Measurement Type\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of observations\", \n                                  \"Mean Temperature (°C)\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the graph, we can see that there is a bigger variability in the maximum temperature recorded at the Tengah weather station in September of the five selected years. This can be observed from the data table as well.\nFrom the 99% confidence interval, it can be observed that the maximum temperature recorded could lie in the range of 31.27°C to 31.99°C, while the minimum temperature recorded could lie in the range of 23.26 °C to 23.85 °C."
  }
]